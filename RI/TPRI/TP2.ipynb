{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import nltk\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5, 1: 9, 2: 9, 3: 9, 4: 5, 5: 11}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('0', 4, 1, 0.16901960800285137),\n",
       " ('000', 2, 1, 0.09389978222380631),\n",
       " ('04', 5, 1, 0.07682709454675062),\n",
       " ('10', 4, 2, 0.33803921600570275),\n",
       " ('100', 2, 2, 0.18779956444761262),\n",
       " ('17', 2, 1, 0.09389978222380631),\n",
       " ('2', 4, 1, 0.16901960800285137),\n",
       " ('2014', 1, 1, 0.09389978222380631),\n",
       " ('2019', 0, 1, 0.16901960800285137),\n",
       " ('2020', 0, 1, 0.16901960800285137),\n",
       " ('3', 0, 1, 0.16901960800285137),\n",
       " ('4', 0, 1, 0.09542425094393249),\n",
       " ('4', 2, 1, 0.05301347274662915),\n",
       " ('4', 4, 1, 0.09542425094393249),\n",
       " ('5', 0, 1, 0.16901960800285137),\n",
       " ('500x', 2, 1, 0.09389978222380631),\n",
       " ('6', 4, 1, 0.16901960800285137),\n",
       " ('7b', 0, 1, 0.16901960800285137),\n",
       " ('abil', 2, 1, 0.09389978222380631),\n",
       " ('achiev', 0, 1, 0.16901960800285137),\n",
       " ('addit', 1, 1, 0.05301347274662915),\n",
       " ('addit', 2, 1, 0.05301347274662915),\n",
       " ('addit', 5, 1, 0.043374659519969314),\n",
       " ('address', 0, 1, 0.07958800173440753),\n",
       " ('address', 1, 1, 0.04421555651911529),\n",
       " ('address', 2, 1, 0.04421555651911529),\n",
       " ('address', 5, 1, 0.03617636442473069),\n",
       " ('adopt', 5, 1, 0.07682709454675062),\n",
       " ('advent', 1, 1, 0.09389978222380631),\n",
       " ('aim', 5, 1, 0.07682709454675062),\n",
       " ('allow', 3, 1, 0.06689555459199582),\n",
       " ('allow', 5, 1, 0.05473272648436022),\n",
       " ('also', 1, 1, 0.04421555651911529),\n",
       " ('also', 2, 1, 0.04421555651911529),\n",
       " ('also', 3, 1, 0.04421555651911529),\n",
       " ('also', 5, 1, 0.03617636442473069),\n",
       " ('although', 0, 1, 0.16901960800285137),\n",
       " ('among', 3, 1, 0.09389978222380631),\n",
       " ('amount', 3, 1, 0.09389978222380631),\n",
       " ('analysi', 1, 1, 0.09389978222380631),\n",
       " ('ann', 4, 5, 0.8450980400142568),\n",
       " ('anno', 2, 1, 0.09389978222380631),\n",
       " ('annot', 2, 6, 0.5633986933428379),\n",
       " ('ap', 5, 1, 0.07682709454675062),\n",
       " ('api', 0, 1, 0.16901960800285137),\n",
       " ('appli', 0, 1, 0.16901960800285137),\n",
       " ('approach', 0, 1, 0.09542425094393249),\n",
       " ('approach', 2, 1, 0.05301347274662915),\n",
       " ('approach', 3, 9, 0.47712125471966244),\n",
       " ('approxim', 4, 1, 0.16901960800285137),\n",
       " ('architectur', 1, 2, 0.18779956444761262),\n",
       " ('art', 4, 1, 0.12041199826559248),\n",
       " ('art', 5, 1, 0.05473272648436022),\n",
       " ('aspect', 2, 1, 0.09389978222380631),\n",
       " ('assembl', 2, 1, 0.09389978222380631),\n",
       " ('assess', 1, 1, 0.09389978222380631),\n",
       " ('attent', 1, 1, 0.09389978222380631),\n",
       " ('author', 2, 1, 0.09389978222380631),\n",
       " ('autoencod', 5, 1, 0.07682709454675062),\n",
       " ('b', 4, 1, 0.16901960800285137),\n",
       " ('base', 1, 7, 0.2663287517506049),\n",
       " ('base', 2, 2, 0.0760939290716014),\n",
       " ('base', 3, 3, 0.1141408936074021),\n",
       " ('base', 4, 2, 0.13696907232888253),\n",
       " ('base', 5, 1, 0.031129334620200573),\n",
       " ('baselin', 5, 1, 0.07682709454675062),\n",
       " ('begin', 3, 1, 0.09389978222380631),\n",
       " ('behind', 0, 2, 0.33803921600570275),\n",
       " ('beir', 3, 1, 0.09389978222380631),\n",
       " ('benchmark', 2, 1, 0.05301347274662915),\n",
       " ('benchmark', 3, 1, 0.05301347274662915),\n",
       " ('benchmark', 4, 2, 0.19084850188786498),\n",
       " ('bert', 1, 3, 0.28169934667141894),\n",
       " ('better', 2, 1, 0.09389978222380631),\n",
       " ('budget', 4, 1, 0.16901960800285137),\n",
       " ('build', 0, 1, 0.16901960800285137),\n",
       " ('built', 0, 1, 0.16901960800285137),\n",
       " ('capabl', 0, 1, 0.12041199826559248),\n",
       " ('capabl', 1, 1, 0.06689555459199582),\n",
       " ('captur', 4, 1, 0.16901960800285137),\n",
       " ('carri', 1, 1, 0.09389978222380631),\n",
       " ('case', 2, 2, 0.18779956444761262),\n",
       " ('cd', 1, 1, 0.09389978222380631),\n",
       " ('chatgpt', 0, 1, 0.16901960800285137),\n",
       " ('clariti', 1, 1, 0.09389978222380631),\n",
       " ('clearli', 1, 1, 0.09389978222380631),\n",
       " ('collect', 2, 1, 0.06689555459199582),\n",
       " ('collect', 5, 1, 0.05473272648436022),\n",
       " ('combin', 1, 1, 0.09389978222380631),\n",
       " ('commonli', 5, 1, 0.07682709454675062),\n",
       " ('compar', 0, 1, 0.07958800173440753),\n",
       " ('compar', 1, 1, 0.04421555651911529),\n",
       " ('compar', 2, 1, 0.04421555651911529),\n",
       " ('compar', 3, 1, 0.04421555651911529),\n",
       " ('competit', 1, 1, 0.09389978222380631),\n",
       " ('complet', 1, 1, 0.09389978222380631),\n",
       " ('complex', 2, 7, 0.6572984755666442),\n",
       " ('compromis', 2, 1, 0.09389978222380631),\n",
       " ('comput', 2, 1, 0.04421555651911529),\n",
       " ('comput', 3, 2, 0.08843111303823058),\n",
       " ('comput', 4, 1, 0.07958800173440753),\n",
       " ('comput', 5, 1, 0.03617636442473069),\n",
       " ('condit', 5, 1, 0.07682709454675062),\n",
       " ('conduct', 1, 1, 0.09389978222380631),\n",
       " ('consid', 3, 1, 0.09389978222380631),\n",
       " ('consider', 3, 1, 0.09389978222380631),\n",
       " ('consist', 2, 1, 0.06689555459199582),\n",
       " ('consist', 3, 1, 0.06689555459199582),\n",
       " ('consumpt', 3, 2, 0.18779956444761262),\n",
       " ('context', 0, 1, 0.16901960800285137),\n",
       " ('contextu', 1, 2, 0.18779956444761262),\n",
       " ('contrast', 4, 1, 0.16901960800285137),\n",
       " ('convers', 3, 1, 0.09389978222380631),\n",
       " ('cost', 2, 2, 0.13379110918399165),\n",
       " ('cost', 3, 1, 0.06689555459199582),\n",
       " ('critic', 2, 1, 0.09389978222380631),\n",
       " ('cross', 1, 1, 0.09389978222380631),\n",
       " ('data', 1, 1, 0.06689555459199582),\n",
       " ('data', 5, 1, 0.05473272648436022),\n",
       " ('dataset', 1, 1, 0.0380469645358007),\n",
       " ('dataset', 2, 6, 0.2282817872148042),\n",
       " ('dataset', 3, 1, 0.0380469645358007),\n",
       " ('dataset', 4, 1, 0.06848453616444126),\n",
       " ('dataset', 5, 1, 0.031129334620200573),\n",
       " ('date', 0, 1, 0.16901960800285137),\n",
       " ('de', 4, 1, 0.16901960800285137),\n",
       " ('deep', 0, 1, 0.09542425094393249),\n",
       " ('deep', 1, 1, 0.05301347274662915),\n",
       " ('deep', 5, 1, 0.043374659519969314),\n",
       " ('deeper', 1, 2, 0.18779956444761262),\n",
       " ('demonstr', 1, 1, 0.04421555651911529),\n",
       " ('demonstr', 3, 2, 0.08843111303823058),\n",
       " ('demonstr', 4, 1, 0.07958800173440753),\n",
       " ('demonstr', 5, 1, 0.03617636442473069),\n",
       " ('dens', 1, 3, 0.20068666377598746),\n",
       " ('dens', 4, 2, 0.24082399653118497),\n",
       " ('design', 1, 1, 0.06689555459199582),\n",
       " ('design', 2, 1, 0.06689555459199582),\n",
       " ('determinist', 0, 1, 0.16901960800285137),\n",
       " ('dev', 4, 2, 0.33803921600570275),\n",
       " ('develop', 2, 1, 0.09389978222380631),\n",
       " ('dimension', 1, 1, 0.09389978222380631),\n",
       " ('discret', 4, 1, 0.16901960800285137),\n",
       " ('disjoint', 4, 1, 0.16901960800285137),\n",
       " ('dl', 3, 1, 0.09389978222380631),\n",
       " ('dl19', 4, 2, 0.33803921600570275),\n",
       " ('document', 1, 7, 0.2663287517506049),\n",
       " ('document', 2, 3, 0.1141408936074021),\n",
       " ('document', 3, 2, 0.0760939290716014),\n",
       " ('document', 4, 5, 0.3424226808222063),\n",
       " ('document', 5, 5, 0.15564667310100286),\n",
       " ('dori', 2, 4, 0.37559912889522523),\n",
       " ('drop', 2, 1, 0.09389978222380631),\n",
       " ('dual', 4, 2, 0.33803921600570275),\n",
       " ('due', 2, 2, 0.18779956444761262),\n",
       " ('effect', 0, 2, 0.13696907232888253),\n",
       " ('effect', 1, 1, 0.0380469645358007),\n",
       " ('effect', 2, 2, 0.0760939290716014),\n",
       " ('effect', 3, 5, 0.1902348226790035),\n",
       " ('effect', 4, 1, 0.06848453616444126),\n",
       " ('effici', 3, 4, 0.2675822183679833),\n",
       " ('effici', 4, 2, 0.24082399653118497),\n",
       " ('effort', 2, 1, 0.09389978222380631),\n",
       " ('ehi', 4, 5, 0.8450980400142568),\n",
       " ('elasticsearch', 1, 1, 0.09389978222380631),\n",
       " ('emb', 4, 1, 0.16901960800285137),\n",
       " ('embed', 1, 3, 0.15904041823988746),\n",
       " ('embed', 4, 5, 0.47712125471966244),\n",
       " ('embed', 5, 2, 0.08674931903993863),\n",
       " ('emerg', 5, 1, 0.07682709454675062),\n",
       " ('empir', 3, 1, 0.09389978222380631),\n",
       " ('employ', 1, 1, 0.09389978222380631),\n",
       " ('encod', 1, 3, 0.20068666377598746),\n",
       " ('encod', 4, 2, 0.24082399653118497),\n",
       " ('end', 4, 2, 0.33803921600570275),\n",
       " ('endpoint', 0, 1, 0.16901960800285137),\n",
       " ('engin', 1, 1, 0.09389978222380631),\n",
       " ('enhanc', 3, 1, 0.09389978222380631),\n",
       " ('ensur', 4, 1, 0.16901960800285137),\n",
       " ('estim', 5, 1, 0.07682709454675062),\n",
       " ('evalu', 2, 2, 0.1060269454932583),\n",
       " ('evalu', 3, 2, 0.1060269454932583),\n",
       " ('evalu', 5, 1, 0.043374659519969314),\n",
       " ('exampl', 4, 1, 0.16901960800285137),\n",
       " ('exist', 2, 1, 0.05301347274662915),\n",
       " ('exist', 3, 1, 0.05301347274662915),\n",
       " ('exist', 5, 1, 0.043374659519969314),\n",
       " ('expans', 1, 2, 0.13379110918399165),\n",
       " ('expans', 5, 4, 0.21893090593744088),\n",
       " ('experi', 1, 1, 0.09389978222380631),\n",
       " ('experiment', 0, 2, 0.24082399653118497),\n",
       " ('experiment', 3, 1, 0.06689555459199582),\n",
       " ('expert', 2, 2, 0.18779956444761262),\n",
       " ('extend', 2, 1, 0.09389978222380631),\n",
       " ('facto', 4, 1, 0.16901960800285137),\n",
       " ('factor', 3, 1, 0.09389978222380631),\n",
       " ('feedback', 5, 2, 0.15365418909350123),\n",
       " ('field', 2, 1, 0.09389978222380631),\n",
       " ('file', 4, 1, 0.16901960800285137),\n",
       " ('final', 1, 2, 0.18779956444761262),\n",
       " ('find', 3, 1, 0.06689555459199582),\n",
       " ('find', 4, 1, 0.12041199826559248),\n",
       " ('fine', 1, 1, 0.09389978222380631),\n",
       " ('first', 0, 1, 0.09542425094393249),\n",
       " ('first', 3, 1, 0.05301347274662915),\n",
       " ('first', 5, 1, 0.043374659519969314),\n",
       " ('fix', 1, 1, 0.09389978222380631),\n",
       " ('focu', 5, 1, 0.07682709454675062),\n",
       " ('foundat', 0, 2, 0.33803921600570275),\n",
       " ('framework', 1, 1, 0.05301347274662915),\n",
       " ('framework', 2, 1, 0.05301347274662915),\n",
       " ('framework', 3, 1, 0.05301347274662915),\n",
       " ('full', 1, 1, 0.09389978222380631),\n",
       " ('fulli', 0, 1, 0.16901960800285137),\n",
       " ('furthermor', 2, 1, 0.09389978222380631),\n",
       " ('futur', 0, 1, 0.16901960800285137),\n",
       " ('gap', 1, 1, 0.06689555459199582),\n",
       " ('gap', 5, 1, 0.05473272648436022),\n",
       " ('gener', 1, 1, 0.06689555459199582),\n",
       " ('gener', 5, 2, 0.10946545296872044),\n",
       " ('given', 4, 2, 0.33803921600570275),\n",
       " ('gov02', 5, 1, 0.07682709454675062),\n",
       " ('gpt', 0, 2, 0.24082399653118497),\n",
       " ('gpt', 2, 1, 0.06689555459199582),\n",
       " ('handl', 2, 2, 0.18779956444761262),\n",
       " ('hidden', 0, 1, 0.16901960800285137),\n",
       " ('hierarch', 4, 1, 0.16901960800285137),\n",
       " ('high', 0, 1, 0.09542425094393249),\n",
       " ('high', 2, 1, 0.05301347274662915),\n",
       " ('high', 3, 3, 0.15904041823988746),\n",
       " ('higher', 5, 1, 0.07682709454675062),\n",
       " ('highlight', 2, 1, 0.09389978222380631),\n",
       " ('hope', 0, 1, 0.16901960800285137),\n",
       " ('howev', 5, 1, 0.07682709454675062),\n",
       " ('human', 2, 1, 0.09389978222380631),\n",
       " ('identifi', 3, 1, 0.09389978222380631),\n",
       " ('ignor', 5, 1, 0.07682709454675062),\n",
       " ('ill', 4, 1, 0.16901960800285137),\n",
       " ('impress', 3, 1, 0.09389978222380631),\n",
       " ('improv', 1, 1, 0.05301347274662915),\n",
       " ('improv', 3, 1, 0.05301347274662915),\n",
       " ('improv', 5, 1, 0.043374659519969314),\n",
       " ('includ', 4, 1, 0.16901960800285137),\n",
       " ('incur', 3, 1, 0.09389978222380631),\n",
       " ('index', 1, 1, 0.06689555459199582),\n",
       " ('index', 4, 2, 0.24082399653118497),\n",
       " ('indic', 3, 1, 0.09389978222380631),\n",
       " ('industri', 4, 2, 0.33803921600570275),\n",
       " ('infer', 3, 1, 0.09389978222380631),\n",
       " ('inform', 0, 1, 0.12041199826559248),\n",
       " ('inform', 5, 1, 0.05473272648436022),\n",
       " ('inher', 3, 1, 0.09389978222380631),\n",
       " ('input', 1, 1, 0.09389978222380631),\n",
       " ('interact', 1, 1, 0.06689555459199582),\n",
       " ('interact', 5, 2, 0.10946545296872044),\n",
       " ('introduc', 2, 1, 0.06689555459199582),\n",
       " ('introduc', 4, 1, 0.12041199826559248),\n",
       " ('invert', 4, 1, 0.16901960800285137),\n",
       " ('ir', 5, 2, 0.15365418909350123),\n",
       " ('ivf', 4, 1, 0.16901960800285137),\n",
       " ('jointli', 4, 1, 0.16901960800285137),\n",
       " ('kind', 3, 1, 0.09389978222380631),\n",
       " ('known', 1, 1, 0.09389978222380631),\n",
       " ('labor', 2, 1, 0.09389978222380631),\n",
       " ('languag', 0, 1, 0.09542425094393249),\n",
       " ('languag', 2, 1, 0.05301347274662915),\n",
       " ('languag', 3, 1, 0.05301347274662915),\n",
       " ('larg', 0, 1, 0.07958800173440753),\n",
       " ('larg', 1, 1, 0.04421555651911529),\n",
       " ('larg', 2, 1, 0.04421555651911529),\n",
       " ('larg', 3, 1, 0.04421555651911529),\n",
       " ('latenc', 3, 1, 0.09389978222380631),\n",
       " ('latent', 5, 2, 0.15365418909350123),\n",
       " ('lead', 4, 1, 0.16901960800285137),\n",
       " ('learn', 0, 1, 0.07958800173440753),\n",
       " ('learn', 1, 2, 0.08843111303823058),\n",
       " ('learn', 4, 5, 0.3979400086720376),\n",
       " ('learn', 5, 2, 0.07235272884946138),\n",
       " ('length', 1, 1, 0.09389978222380631),\n",
       " ('lengthi', 1, 1, 0.09389978222380631),\n",
       " ('level', 2, 2, 0.18779956444761262),\n",
       " ('leverag', 1, 1, 0.06689555459199582),\n",
       " ('leverag', 5, 1, 0.05473272648436022),\n",
       " ('like', 3, 1, 0.06689555459199582),\n",
       " ('like', 4, 1, 0.12041199826559248),\n",
       " ('limit', 1, 1, 0.06689555459199582),\n",
       " ('limit', 2, 1, 0.06689555459199582),\n",
       " ('listwis', 0, 1, 0.12041199826559248),\n",
       " ('listwis', 3, 1, 0.06689555459199582),\n",
       " ('llm', 0, 3, 0.28627275283179743),\n",
       " ('llm', 2, 2, 0.1060269454932583),\n",
       " ('llm', 3, 5, 0.2650673637331458),\n",
       " ('low', 1, 1, 0.09389978222380631),\n",
       " ('mae', 2, 4, 0.37559912889522523),\n",
       " ('mani', 5, 1, 0.07682709454675062),\n",
       " ('map', 5, 1, 0.07682709454675062),\n",
       " ('marco', 4, 2, 0.24082399653118497),\n",
       " ('marco', 5, 1, 0.05473272648436022),\n",
       " ('match', 1, 2, 0.13379110918399165),\n",
       " ('match', 5, 1, 0.05473272648436022),\n",
       " ('maximum', 1, 1, 0.09389978222380631),\n",
       " ('method', 2, 1, 0.05301347274662915),\n",
       " ('method', 3, 1, 0.05301347274662915),\n",
       " ('method', 4, 1, 0.09542425094393249),\n",
       " ('might', 4, 1, 0.16901960800285137),\n",
       " ('model', 0, 3, 0.1806179973983887),\n",
       " ('model', 1, 7, 0.2341344410719854),\n",
       " ('model', 2, 1, 0.03344777729599791),\n",
       " ('model', 3, 2, 0.06689555459199582),\n",
       " ('model', 4, 1, 0.06020599913279624),\n",
       " ('model', 5, 11, 0.3010299956639812),\n",
       " ('modern', 0, 1, 0.16901960800285137),\n",
       " ('mostli', 0, 1, 0.16901960800285137),\n",
       " ('mrr', 4, 1, 0.16901960800285137),\n",
       " ('ms', 4, 2, 0.24082399653118497),\n",
       " ('ms', 5, 1, 0.05473272648436022),\n",
       " ('much', 0, 1, 0.16901960800285137),\n",
       " ('multi', 2, 2, 0.18779956444761262),\n",
       " ('multifacet', 2, 2, 0.18779956444761262),\n",
       " ('natur', 2, 1, 0.09389978222380631),\n",
       " ('ndcg', 4, 1, 0.16901960800285137),\n",
       " ('nearest', 4, 1, 0.16901960800285137),\n",
       " ('need', 2, 1, 0.09389978222380631),\n",
       " ('neighbor', 4, 1, 0.16901960800285137),\n",
       " ('neural', 5, 3, 0.23048128364025183),\n",
       " ('non', 0, 1, 0.16901960800285137),\n",
       " ('notabl', 2, 1, 0.09389978222380631),\n",
       " ('notion', 4, 1, 0.16901960800285137),\n",
       " ('novel', 2, 1, 0.06689555459199582),\n",
       " ('novel', 3, 1, 0.06689555459199582),\n",
       " ('number', 3, 1, 0.09389978222380631),\n",
       " ('observ', 2, 1, 0.09389978222380631),\n",
       " ('obtain', 4, 1, 0.16901960800285137),\n",
       " ('off', 3, 1, 0.09389978222380631),\n",
       " ('often', 5, 1, 0.07682709454675062),\n",
       " ('ohsum', 1, 1, 0.09389978222380631),\n",
       " ('opaqu', 0, 1, 0.16901960800285137),\n",
       " ('open', 0, 1, 0.16901960800285137),\n",
       " ('optim', 4, 1, 0.16901960800285137),\n",
       " ('other', 3, 1, 0.09389978222380631),\n",
       " ('outcom', 0, 1, 0.16901960800285137),\n",
       " ('outperform', 4, 1, 0.12041199826559248),\n",
       " ('outperform', 5, 1, 0.05473272648436022),\n",
       " ('overhead', 3, 1, 0.09389978222380631),\n",
       " ('pair', 5, 1, 0.07682709454675062),\n",
       " ('pairwis', 3, 2, 0.18779956444761262),\n",
       " ('paramet', 0, 1, 0.16901960800285137),\n",
       " ('passag', 5, 1, 0.07682709454675062),\n",
       " ('path', 4, 1, 0.16901960800285137),\n",
       " ('perform', 0, 1, 0.06848453616444126),\n",
       " ('perform', 1, 2, 0.0760939290716014),\n",
       " ('perform', 2, 2, 0.0760939290716014),\n",
       " ('perform', 4, 2, 0.13696907232888253),\n",
       " ('perform', 5, 1, 0.031129334620200573),\n",
       " ('phrase', 1, 2, 0.18779956444761262),\n",
       " ('pipelin', 1, 1, 0.09389978222380631),\n",
       " ('pointwis', 3, 2, 0.18779956444761262),\n",
       " ('poor', 3, 1, 0.09389978222380631),\n",
       " ('posit', 4, 1, 0.16901960800285137),\n",
       " ('present', 0, 1, 0.16901960800285137),\n",
       " ('primarili', 2, 1, 0.09389978222380631),\n",
       " ('problem', 4, 1, 0.16901960800285137),\n",
       " ('procedur', 3, 1, 0.09389978222380631),\n",
       " ('process', 4, 1, 0.16901960800285137),\n",
       " ('produc', 1, 2, 0.13379110918399165),\n",
       " ('produc', 2, 1, 0.06689555459199582),\n",
       " ('prompt', 3, 3, 0.28169934667141894),\n",
       " ('propos', 1, 1, 0.0380469645358007),\n",
       " ('propos', 2, 1, 0.0380469645358007),\n",
       " ('propos', 3, 2, 0.0760939290716014),\n",
       " ('propos', 4, 1, 0.06848453616444126),\n",
       " ('propos', 5, 3, 0.09338800386060171),\n",
       " ('proprietari', 0, 1, 0.16901960800285137),\n",
       " ('provid', 0, 1, 0.16901960800285137),\n",
       " ('pseudo', 5, 1, 0.07682709454675062),\n",
       " ('qe', 5, 4, 0.30730837818700246),\n",
       " ('qualiti', 0, 1, 0.12041199826559248),\n",
       " ('qualiti', 2, 1, 0.06689555459199582),\n",
       " ('queri', 1, 9, 0.3979400086720376),\n",
       " ('queri', 2, 9, 0.3979400086720376),\n",
       " ('queri', 4, 5, 0.3979400086720376),\n",
       " ('queri', 5, 5, 0.18088182212365345),\n",
       " ('rank', 1, 1, 0.0380469645358007),\n",
       " ('rank', 2, 1, 0.0380469645358007),\n",
       " ('rank', 3, 7, 0.2663287517506049),\n",
       " ('rank', 4, 1, 0.06848453616444126),\n",
       " ('rank', 5, 2, 0.062258669240401146),\n",
       " ('rankvicuna', 0, 1, 0.16901960800285137),\n",
       " ('recent', 2, 1, 0.06689555459199582),\n",
       " ('recent', 5, 1, 0.05473272648436022),\n",
       " ('recogn', 2, 1, 0.09389978222380631),\n",
       " ('record', 1, 1, 0.09389978222380631),\n",
       " ('reduc', 1, 1, 0.06689555459199582),\n",
       " ('reduc', 3, 2, 0.13379110918399165),\n",
       " ('reduct', 2, 1, 0.09389978222380631),\n",
       " ('relev', 1, 1, 0.04421555651911529),\n",
       " ('relev', 2, 3, 0.13264666955734586),\n",
       " ('relev', 4, 1, 0.07958800173440753),\n",
       " ('relev', 5, 3, 0.10852909327419206),\n",
       " ('remain', 0, 1, 0.16901960800285137),\n",
       " ('repres', 1, 1, 0.06689555459199582),\n",
       " ('repres', 2, 1, 0.06689555459199582),\n",
       " ('represent', 1, 3, 0.28169934667141894),\n",
       " ('reproduc', 0, 1, 0.16901960800285137),\n",
       " ('requir', 2, 2, 0.18779956444761262),\n",
       " ('rerank', 0, 5, 0.8450980400142568),\n",
       " ('research', 0, 2, 0.19084850188786498),\n",
       " ('research', 2, 3, 0.15904041823988746),\n",
       " ('research', 5, 2, 0.08674931903993863),\n",
       " ('resourc', 2, 1, 0.09389978222380631),\n",
       " ('result', 0, 2, 0.13696907232888253),\n",
       " ('result', 1, 3, 0.1141408936074021),\n",
       " ('result', 2, 1, 0.0380469645358007),\n",
       " ('result', 3, 1, 0.0380469645358007),\n",
       " ('result', 5, 1, 0.031129334620200573),\n",
       " ('retain', 3, 1, 0.09389978222380631),\n",
       " ('retriev', 0, 1, 0.06848453616444126),\n",
       " ('retriev', 1, 3, 0.1141408936074021),\n",
       " ('retriev', 2, 3, 0.1141408936074021),\n",
       " ('retriev', 4, 2, 0.13696907232888253),\n",
       " ('retriev', 5, 1, 0.031129334620200573),\n",
       " ('richer', 1, 1, 0.09389978222380631),\n",
       " ('robust', 5, 1, 0.07682709454675062),\n",
       " ('sbert', 1, 1, 0.09389978222380631),\n",
       " ('scalabl', 2, 1, 0.09389978222380631),\n",
       " ('scienc', 2, 1, 0.09389978222380631),\n",
       " ('scientif', 2, 4, 0.37559912889522523),\n",
       " ('score', 2, 1, 0.06689555459199582),\n",
       " ('score', 3, 1, 0.06689555459199582),\n",
       " ('search', 1, 1, 0.06689555459199582),\n",
       " ('search', 4, 2, 0.24082399653118497),\n",
       " ('self', 1, 1, 0.09389978222380631),\n",
       " ('semant', 1, 2, 0.1060269454932583),\n",
       " ('semant', 4, 1, 0.09542425094393249),\n",
       " ('semant', 5, 1, 0.043374659519969314),\n",
       " ('sentenc', 1, 1, 0.09389978222380631),\n",
       " ('separ', 1, 2, 0.18779956444761262),\n",
       " ('set', 0, 1, 0.12041199826559248),\n",
       " ('set', 4, 2, 0.24082399653118497),\n",
       " ('setwis', 3, 1, 0.09389978222380631),\n",
       " ('sever', 4, 1, 0.16901960800285137),\n",
       " ('shaki', 0, 1, 0.16901960800285137),\n",
       " ('short', 1, 1, 0.09389978222380631),\n",
       " ('shortcom', 0, 1, 0.16901960800285137),\n",
       " ('shot', 0, 2, 0.24082399653118497),\n",
       " ('shot', 3, 6, 0.4013733275519749),\n",
       " ('show', 0, 1, 0.12041199826559248),\n",
       " ('show', 5, 1, 0.05473272648436022),\n",
       " ('signific', 0, 1, 0.12041199826559248),\n",
       " ('signific', 2, 1, 0.06689555459199582),\n",
       " ('significantli', 3, 1, 0.09389978222380631),\n",
       " ('similar', 4, 1, 0.12041199826559248),\n",
       " ('similar', 5, 1, 0.05473272648436022),\n",
       " ('size', 1, 1, 0.06689555459199582),\n",
       " ('size', 3, 1, 0.06689555459199582),\n",
       " ('slightli', 0, 1, 0.16901960800285137),\n",
       " ('smaller', 0, 1, 0.16901960800285137),\n",
       " ('sota', 4, 1, 0.16901960800285137),\n",
       " ('sourc', 0, 1, 0.16901960800285137),\n",
       " ('space', 1, 2, 0.13379110918399165),\n",
       " ('space', 5, 2, 0.10946545296872044),\n",
       " ('specif', 1, 1, 0.09389978222380631),\n",
       " ('stabl', 4, 1, 0.16901960800285137),\n",
       " ('stage', 4, 2, 0.33803921600570275),\n",
       " ('standard', 4, 3, 0.3612359947967774),\n",
       " ('standard', 5, 1, 0.05473272648436022),\n",
       " ('state', 4, 1, 0.12041199826559248),\n",
       " ('state', 5, 1, 0.05473272648436022),\n",
       " ('structur', 2, 1, 0.06689555459199582),\n",
       " ('structur', 4, 3, 0.3612359947967774),\n",
       " ('studi', 1, 2, 0.13379110918399165),\n",
       " ('studi', 3, 1, 0.06689555459199582),\n",
       " ('style', 4, 1, 0.16901960800285137),\n",
       " ('sub', 2, 1, 0.09389978222380631),\n",
       " ('suboptim', 4, 1, 0.16901960800285137),\n",
       " ('success', 0, 1, 0.16901960800285137),\n",
       " ('suffer', 3, 1, 0.09389978222380631),\n",
       " ('suit', 4, 1, 0.16901960800285137),\n",
       " ('summar', 1, 1, 0.09389978222380631),\n",
       " ('superior', 3, 1, 0.09389978222380631),\n",
       " ('task', 2, 3, 0.20068666377598746),\n",
       " ('task', 3, 1, 0.06689555459199582),\n",
       " ('techniqu', 4, 1, 0.16901960800285137),\n",
       " ('term', 5, 1, 0.07682709454675062),\n",
       " ('test', 2, 1, 0.05301347274662915),\n",
       " ('test', 3, 1, 0.05301347274662915),\n",
       " ('test', 5, 1, 0.043374659519969314),\n",
       " ('text', 1, 4, 0.37559912889522523),\n",
       " ('thoroughli', 3, 1, 0.09389978222380631),\n",
       " ('threaten', 0, 1, 0.16901960800285137),\n",
       " ('three', 5, 1, 0.07682709454675062),\n",
       " ('tier', 2, 1, 0.09389978222380631),\n",
       " ('time', 5, 1, 0.07682709454675062),\n",
       " ('token', 1, 1, 0.06689555459199582),\n",
       " ('token', 3, 2, 0.13379110918399165),\n",
       " ('track', 0, 1, 0.16901960800285137),\n",
       " ('trade', 3, 1, 0.09389978222380631),\n",
       " ('tradit', 2, 1, 0.06689555459199582),\n",
       " ('tradit', 5, 2, 0.10946545296872044),\n",
       " ('train', 4, 1, 0.12041199826559248),\n",
       " ('train', 5, 1, 0.05473272648436022),\n",
       " ('transform', 1, 3, 0.28169934667141894),\n",
       " ('trec', 0, 1, 0.06848453616444126),\n",
       " ('trec', 1, 1, 0.0380469645358007),\n",
       " ('trec', 3, 1, 0.0380469645358007),\n",
       " ('trec', 4, 2, 0.13696907232888253),\n",
       " ('trec', 5, 1, 0.031129334620200573),\n",
       " ('tree', 4, 3, 0.5070588240085541),\n",
       " ('tune', 1, 1, 0.09389978222380631),\n",
       " ('two', 1, 1, 0.06689555459199582),\n",
       " ('two', 4, 2, 0.24082399653118497),\n",
       " ('understand', 1, 2, 0.18779956444761262),\n",
       " ('us', 3, 1, 0.09389978222380631),\n",
       " ('use', 1, 2, 0.0760939290716014),\n",
       " ('use', 2, 1, 0.0380469645358007),\n",
       " ('use', 3, 1, 0.0380469645358007),\n",
       " ('use', 4, 2, 0.13696907232888253),\n",
       " ('use', 5, 3, 0.09338800386060171),\n",
       " ('user', 2, 1, 0.09389978222380631),\n",
       " ('valid', 2, 1, 0.09389978222380631),\n",
       " ('variat', 5, 1, 0.07682709454675062),\n",
       " ('vector', 1, 5, 0.4694989111190316),\n",
       " ('verac', 0, 1, 0.16901960800285137),\n",
       " ('versa', 4, 1, 0.16901960800285137),\n",
       " ('vice', 4, 1, 0.16901960800285137),\n",
       " ('web', 4, 1, 0.16901960800285137),\n",
       " ('well', 1, 1, 0.09389978222380631),\n",
       " ('within', 2, 1, 0.06689555459199582),\n",
       " ('within', 3, 1, 0.06689555459199582),\n",
       " ('without', 2, 2, 0.18779956444761262),\n",
       " ('work', 0, 2, 0.24082399653118497),\n",
       " ('work', 4, 1, 0.12041199826559248),\n",
       " ('year', 5, 1, 0.07682709454675062),\n",
       " ('yield', 0, 1, 0.12041199826559248),\n",
       " ('yield', 1, 1, 0.06689555459199582),\n",
       " ('zero', 0, 2, 0.24082399653118497),\n",
       " ('zero', 3, 6, 0.4013733275519749)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Docs:\n",
    "\n",
    "    def __init__(self,Lancaster=True,split=False):\n",
    "\n",
    "        docs = []\n",
    "        self.maxfreq = {}\n",
    "        MotsVides = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "        self.files = [\"TP2data/D1.txt\",\"TP2data/D2.txt\",\"TP2data/D3.txt\",\"TP2data/D4.txt\",\"TP2data/D5.txt\",\"TP2data/D6.txt\"]\n",
    "        file = \"\"\n",
    "        my_dict = {}\n",
    "        for i in range(len(self.files)):\n",
    "            file = open(self.files[i]).read()\n",
    "            file = file.replace(\"\\n\",\"\")\n",
    "\n",
    "            if split :\n",
    "                TermesNormalisation = file.split()\n",
    "            else :\n",
    "\n",
    "                ExpReg = nltk.RegexpTokenizer('(?:[A-Z]\\.)+|\\w+') # \\d : équivalent à [0-9] >>> \n",
    "                Termes = ExpReg.tokenize(file) \n",
    "\n",
    "            if Lancaster :\n",
    "                TermesSansMotsVides = [terme for terme in Termes if terme.lower() not in MotsVides]\n",
    "                Lancaster = nltk.LancasterStemmer()\n",
    "                TermesNormalisation = [Lancaster.stem(terme) for terme in TermesSansMotsVides]\n",
    "            else :\n",
    "                TermesSansMotsVides = [terme for terme in Termes if terme.lower() not in MotsVides]\n",
    "                porter = nltk.PorterStemmer()\n",
    "                TermesNormalisation = [porter.stem(terme) for terme in TermesSansMotsVides]\n",
    "\n",
    "\n",
    "            for term in TermesNormalisation:\n",
    "                \n",
    "                if (term,i) in my_dict:\n",
    "                    my_dict[(term,i)] += 1\n",
    "                else:\n",
    "                    my_dict[(term,i)] = 1\n",
    "\n",
    "        self.dict = my_dict\n",
    "\n",
    "\n",
    "        for keys in self.dict.keys():\n",
    "            if keys[1] not in docs:\n",
    "                docs.append(keys[1])\n",
    "            if keys[1] not in self.maxfreq.keys():\n",
    "                self.maxfreq[keys[1]] = 0\n",
    "            if self.dict[keys] > self.maxfreq[keys[1]]:\n",
    "                self.maxfreq[keys[1]] = self.dict[keys]\n",
    "\n",
    "        print(self.maxfreq)\n",
    "        self.N = len(docs)\n",
    "    \n",
    "    def rebuild(self,Lancaster=True,split=False):\n",
    "        docs = []\n",
    "        self.maxfreq = {}\n",
    "        MotsVides = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "        \n",
    "        file = \"\"\n",
    "        my_dict = {}\n",
    "        for i in range(len(self.files)):\n",
    "            file = open(self.files[i]).read()\n",
    "            file = file.replace(\"\\n\",\"\")\n",
    "\n",
    "\n",
    "            if not split :\n",
    "                Termes = file.split()\n",
    "            else :\n",
    "                ExpReg = nltk.RegexpTokenizer('(?:[A-Z]\\.)+|\\w+|\\.{3}') # \\d : équivalent à [0-9] >>> \n",
    "                Termes = ExpReg.tokenize(file) \n",
    "            \n",
    "\n",
    "            if Lancaster :\n",
    "                TermesSansMotsVides = [terme for terme in Termes if terme.lower() not in MotsVides]\n",
    "                Lancaster = nltk.LancasterStemmer()\n",
    "                TermesNormalisation = [Lancaster.stem(terme) for terme in TermesSansMotsVides]\n",
    "            else :\n",
    "                TermesSansMotsVides = [terme for terme in Termes if terme.lower() not in MotsVides]\n",
    "                porter = nltk.PorterStemmer()\n",
    "                TermesNormalisation = [porter.stem(terme) for terme in TermesSansMotsVides]\n",
    "\n",
    "            for term in TermesNormalisation:\n",
    "                \n",
    "                if (term,i) in my_dict:\n",
    "                    my_dict[(term,i)] += 1\n",
    "                else:\n",
    "                    my_dict[(term,i)] = 1\n",
    "\n",
    "        self.dict = my_dict\n",
    "\n",
    "\n",
    "        for keys in self.dict.keys():\n",
    "            if keys[1] not in docs:\n",
    "                docs.append(keys[1])\n",
    "            if keys[1] not in self.maxfreq.keys():\n",
    "                self.maxfreq[keys[1]] = 0\n",
    "            if self.dict[keys] > self.maxfreq[keys[1]]:\n",
    "                self.maxfreq[keys[1]] = self.dict[keys]\n",
    "\n",
    "        self.N = len(docs)\n",
    "        self.DictWeight()\n",
    "\n",
    "    def calcWeight(self,word,doc):\n",
    "\n",
    "        inDocs = []\n",
    "\n",
    "        for keys in self.dict.keys():\n",
    "            if keys[0] == word:\n",
    "                if keys[1] not in inDocs:\n",
    "                    inDocs.append(keys[1])\n",
    "\n",
    "        # nombre de documents contenant le mot\n",
    "        Ni = len(inDocs)\n",
    "\n",
    "        try:\n",
    "            tf = self.dict[(word,doc)]/self.maxfreq[doc]\n",
    "        except:\n",
    "            tf = 0\n",
    "            \n",
    "        #idf = math.log10((N/Ni)+1)\n",
    "        try:\n",
    "            idf = math.log10((self.N/Ni)+1)\n",
    "        except:\n",
    "            idf = 0\n",
    "\n",
    "        return(tf*idf)\n",
    "\n",
    "    def DictWeight(self):\n",
    "        self.TDFP = [(word,doc,self.dict[(word,doc)],self.calcWeight(word,doc)) for word,doc in self.dict.keys()]\n",
    "        self.DTFP = [(doc,word,freq,weight) for word,doc,freq,weight in self.TDFP]\n",
    "        self.TDFP = sorted(self.TDFP, key=lambda x: x[0])\n",
    "\n",
    "        \n",
    "d = Docs(Lancaster=False)\n",
    "\n",
    "d.DictWeight()\n",
    "\n",
    "d.TDFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\APPS\\python\\lib\\tkinter\\__init__.py\", line 1884, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\Mekki\\AppData\\Local\\Temp\\ipykernel_11496\\2791770733.py\", line 27, in on_token_change\n",
      "    search()\n",
      "  File \"C:\\Users\\Mekki\\AppData\\Local\\Temp\\ipykernel_11496\\2791770733.py\", line 7, in search\n",
      "    table.delete(*table.get_children())\n",
      "  File \"d:\\APPS\\python\\lib\\tkinter\\ttk.py\", line 1225, in get_children\n",
      "    self.tk.call(self._w, \"children\", item or '') or ())\n",
      "_tkinter.TclError: invalid command name \".!frame.!treeview\"\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "\n",
    "def search():\n",
    "\n",
    "    text = query_text.get()\n",
    "    table.delete(*table.get_children())\n",
    "\n",
    "    if index_var.get() == 0:\n",
    "        data = d.TDFP\n",
    "    else:\n",
    "        data = d.DTFP\n",
    "\n",
    "    for terme in data:\n",
    "\n",
    "        if type(terme[0]) is str:\n",
    "            if text.lower() in terme[0].lower():\n",
    "                table.insert(\"\", \"end\", values=[terme[0],terme[1],terme[2],terme[3]])\n",
    "        else:\n",
    "            if text.lower() in terme[1].lower():\n",
    "                table.insert(\"\", \"end\", values=[terme[0],terme[1],terme[2],terme[3]])\n",
    "    # Add your search and processing logic here\n",
    "    pass\n",
    "\n",
    "def on_token_change(*args):\n",
    "    d.rebuild(Lancaster=stemming.get(),split=token.get())\n",
    "    search()\n",
    "\n",
    "def on_index_change(*args):\n",
    "    search()\n",
    "\n",
    "# Create the main application window\n",
    "root = tk.Tk()\n",
    "root.title(\"Text Processing Application\")\n",
    "\n",
    "# Search Query Text Box and Search Button\n",
    "query_label = tk.Label(root, text=\"Search Query:\")\n",
    "query_label.grid(row=0, column=0)\n",
    "query_text = tk.Entry(root, width=40)\n",
    "query_text.grid(row=0, column=1)\n",
    "search_button = tk.Button(root, text=\"Search\", command=search)\n",
    "search_button.grid(row=0, column=2)\n",
    "\n",
    "# Border around \"Processing\" section\n",
    "processing_label_frame = ttk.LabelFrame(root, text=\"Processing\")\n",
    "processing_label_frame.grid(row=1, column=2, padx=10, pady=10)\n",
    "\n",
    "# Radio buttons for Processing\n",
    "stemming = tk.IntVar()\n",
    "stemming.trace(\"w\", on_token_change)\n",
    "\n",
    "token = tk.IntVar()\n",
    "token.trace(\"w\", on_token_change)\n",
    "\n",
    "tokenization_radiobutton = tk.Checkbutton(processing_label_frame, text=\"Tokenization\", variable=token)\n",
    "porter_stemmer_radiobutton = tk.Checkbutton(processing_label_frame, text=\"Lancaster Stemmer\", variable=stemming)\n",
    "porter_stemmer_radiobutton.select()\n",
    "tokenization_radiobutton.grid(row=0, column=0)\n",
    "porter_stemmer_radiobutton.grid(row=1, column=0)\n",
    "\n",
    "# Border around \"Index\" section\n",
    "index_label_frame = ttk.LabelFrame(root, text=\"Index\")\n",
    "index_label_frame.grid(row=1, column=0, padx=10, pady=10)\n",
    "\n",
    "# Radio buttons for Index\n",
    "\n",
    "index_var = tk.IntVar()\n",
    "index_var.trace(\"w\", on_index_change)\n",
    "\n",
    "docs_per_term_radiobutton = tk.Radiobutton(index_label_frame, text=\"DOCS per TERM\", variable=index_var, value=0)\n",
    "terms_per_doc_radiobutton = tk.Radiobutton(index_label_frame, text=\"TERMS per DOC\", variable=index_var, value=1)\n",
    "docs_per_term_radiobutton.grid(row=1, column=0)\n",
    "terms_per_doc_radiobutton.grid(row=2, column=0)\n",
    "\n",
    "# Table to display data\n",
    "table_frame = ttk.Frame(root)\n",
    "table_frame.grid(row=2, column=0, columnspan=3, pady=10)\n",
    "table = ttk.Treeview(table_frame, columns=(\"1\", \"2\", \"3\", \"4\"))\n",
    "table.heading(\"#1\", text=\"terme\")\n",
    "table.heading(\"#2\", text=\"document\")\n",
    "table.heading(\"#3\", text=\"freq\")\n",
    "table.heading(\"#4\", text=\"Score\")\n",
    "table['show'] = 'headings'\n",
    "# Vertical scrollbar for the table\n",
    "table_scrollbar = ttk.Scrollbar(table_frame, orient=\"vertical\", command=table.yview)\n",
    "table.configure(yscrollcommand=table_scrollbar.set)\n",
    "\n",
    "# Grid layout for the table and scrollbar\n",
    "table.grid(row=0, column=0, sticky=\"nsew\")\n",
    "table_scrollbar.grid(row=0, column=1, sticky=\"ns\")\n",
    "\n",
    "\n",
    "# Make the table resizable\n",
    "table_frame.grid_rowconfigure(0, weight=1)\n",
    "table_frame.grid_columnconfigure(0, weight=1)\n",
    "\n",
    "\n",
    "for dat in d.TDFP:\n",
    "    table.insert(\"\", \"end\", values=[dat[0],dat[1],dat[2],dat[3]])\n",
    "\n",
    "\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
