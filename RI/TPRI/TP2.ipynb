{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import nltk\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:20: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:66: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:20: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:66: SyntaxWarning: invalid escape sequence '\\.'\n",
      "C:\\Users\\mekki\\AppData\\Local\\Temp\\ipykernel_6704\\4079350013.py:20: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  ExpReg = nltk.RegexpTokenizer('(?:[A-Z]\\.)+|\\w+') # \\d : équivalent à [0-9] >>>\n",
      "C:\\Users\\mekki\\AppData\\Local\\Temp\\ipykernel_6704\\4079350013.py:66: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  ExpReg = nltk.RegexpTokenizer('(?:[A-Z]\\.)+|\\w+|\\.{3}') # \\d : équivalent à [0-9] >>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('0', 4, 1, 0.07682709454675062),\n",
       " ('000', 2, 1, 0.07682709454675062),\n",
       " ('04', 5, 1, 0.07682709454675062),\n",
       " ('10', 4, 2, 0.15365418909350123),\n",
       " ('100', 2, 2, 0.15365418909350123),\n",
       " ('17', 2, 1, 0.07682709454675062),\n",
       " ('2', 4, 1, 0.07682709454675062),\n",
       " ('2014', 1, 1, 0.07682709454675062),\n",
       " ('2019', 0, 1, 0.07682709454675062),\n",
       " ('2020', 0, 1, 0.07682709454675062),\n",
       " ('3', 0, 1, 0.07682709454675062),\n",
       " ('4', 0, 1, 0.043374659519969314),\n",
       " ('4', 2, 1, 0.043374659519969314),\n",
       " ('4', 4, 1, 0.043374659519969314),\n",
       " ('5', 0, 1, 0.07682709454675062),\n",
       " ('500x', 2, 1, 0.07682709454675062),\n",
       " ('6', 4, 1, 0.07682709454675062),\n",
       " ('7b', 0, 1, 0.07682709454675062),\n",
       " ('abil', 2, 1, 0.07682709454675062),\n",
       " ('achiev', 0, 1, 0.07682709454675062),\n",
       " ('addit', 1, 1, 0.043374659519969314),\n",
       " ('addit', 2, 1, 0.043374659519969314),\n",
       " ('addit', 5, 1, 0.043374659519969314),\n",
       " ('address', 0, 1, 0.03617636442473069),\n",
       " ('address', 1, 1, 0.03617636442473069),\n",
       " ('address', 2, 1, 0.03617636442473069),\n",
       " ('address', 5, 1, 0.03617636442473069),\n",
       " ('adopt', 5, 1, 0.07682709454675062),\n",
       " ('advent', 1, 1, 0.07682709454675062),\n",
       " ('aim', 5, 1, 0.07682709454675062),\n",
       " ('allow', 3, 1, 0.05473272648436022),\n",
       " ('allow', 5, 1, 0.05473272648436022),\n",
       " ('also', 1, 1, 0.03617636442473069),\n",
       " ('also', 2, 1, 0.03617636442473069),\n",
       " ('also', 3, 1, 0.03617636442473069),\n",
       " ('also', 5, 1, 0.03617636442473069),\n",
       " ('although', 0, 1, 0.07682709454675062),\n",
       " ('among', 3, 1, 0.07682709454675062),\n",
       " ('amount', 3, 1, 0.07682709454675062),\n",
       " ('analysi', 1, 1, 0.07682709454675062),\n",
       " ('ann', 4, 5, 0.3841354727337531),\n",
       " ('anno', 2, 1, 0.07682709454675062),\n",
       " ('annot', 2, 6, 0.46096256728050367),\n",
       " ('ap', 5, 1, 0.07682709454675062),\n",
       " ('api', 0, 1, 0.07682709454675062),\n",
       " ('appli', 0, 1, 0.07682709454675062),\n",
       " ('approach', 0, 1, 0.043374659519969314),\n",
       " ('approach', 2, 1, 0.043374659519969314),\n",
       " ('approach', 3, 9, 0.39037193567972384),\n",
       " ('approxim', 4, 1, 0.07682709454675062),\n",
       " ('architectur', 1, 2, 0.15365418909350123),\n",
       " ('art', 4, 1, 0.05473272648436022),\n",
       " ('art', 5, 1, 0.05473272648436022),\n",
       " ('aspect', 2, 1, 0.07682709454675062),\n",
       " ('assembl', 2, 1, 0.07682709454675062),\n",
       " ('assess', 1, 1, 0.07682709454675062),\n",
       " ('attent', 1, 1, 0.07682709454675062),\n",
       " ('author', 2, 1, 0.07682709454675062),\n",
       " ('autoencod', 5, 1, 0.07682709454675062),\n",
       " ('b', 4, 1, 0.07682709454675062),\n",
       " ('base', 1, 7, 0.217905342341404),\n",
       " ('base', 2, 2, 0.062258669240401146),\n",
       " ('base', 3, 3, 0.09338800386060171),\n",
       " ('base', 4, 2, 0.062258669240401146),\n",
       " ('base', 5, 1, 0.031129334620200573),\n",
       " ('baselin', 5, 1, 0.07682709454675062),\n",
       " ('begin', 3, 1, 0.07682709454675062),\n",
       " ('behind', 0, 2, 0.15365418909350123),\n",
       " ('beir', 3, 1, 0.07682709454675062),\n",
       " ('benchmark', 2, 1, 0.043374659519969314),\n",
       " ('benchmark', 3, 1, 0.043374659519969314),\n",
       " ('benchmark', 4, 2, 0.08674931903993863),\n",
       " ('bert', 1, 3, 0.23048128364025183),\n",
       " ('better', 2, 1, 0.07682709454675062),\n",
       " ('budget', 4, 1, 0.07682709454675062),\n",
       " ('build', 0, 1, 0.07682709454675062),\n",
       " ('built', 0, 1, 0.07682709454675062),\n",
       " ('capabl', 0, 1, 0.05473272648436022),\n",
       " ('capabl', 1, 1, 0.05473272648436022),\n",
       " ('captur', 4, 1, 0.07682709454675062),\n",
       " ('carri', 1, 1, 0.07682709454675062),\n",
       " ('case', 2, 2, 0.15365418909350123),\n",
       " ('cd', 1, 1, 0.07682709454675062),\n",
       " ('chatgpt', 0, 1, 0.07682709454675062),\n",
       " ('clariti', 1, 1, 0.07682709454675062),\n",
       " ('clearli', 1, 1, 0.07682709454675062),\n",
       " ('collect', 2, 1, 0.05473272648436022),\n",
       " ('collect', 5, 1, 0.05473272648436022),\n",
       " ('combin', 1, 1, 0.07682709454675062),\n",
       " ('commonli', 5, 1, 0.07682709454675062),\n",
       " ('compar', 0, 1, 0.03617636442473069),\n",
       " ('compar', 1, 1, 0.03617636442473069),\n",
       " ('compar', 2, 1, 0.03617636442473069),\n",
       " ('compar', 3, 1, 0.03617636442473069),\n",
       " ('competit', 1, 1, 0.07682709454675062),\n",
       " ('complet', 1, 1, 0.07682709454675062),\n",
       " ('complex', 2, 7, 0.5377896618272543),\n",
       " ('compromis', 2, 1, 0.07682709454675062),\n",
       " ('comput', 2, 1, 0.03617636442473069),\n",
       " ('comput', 3, 2, 0.07235272884946138),\n",
       " ('comput', 4, 1, 0.03617636442473069),\n",
       " ('comput', 5, 1, 0.03617636442473069),\n",
       " ('condit', 5, 1, 0.07682709454675062),\n",
       " ('conduct', 1, 1, 0.07682709454675062),\n",
       " ('consid', 3, 1, 0.07682709454675062),\n",
       " ('consider', 3, 1, 0.07682709454675062),\n",
       " ('consist', 2, 1, 0.05473272648436022),\n",
       " ('consist', 3, 1, 0.05473272648436022),\n",
       " ('consumpt', 3, 2, 0.15365418909350123),\n",
       " ('context', 0, 1, 0.07682709454675062),\n",
       " ('contextu', 1, 2, 0.15365418909350123),\n",
       " ('contrast', 4, 1, 0.07682709454675062),\n",
       " ('convers', 3, 1, 0.07682709454675062),\n",
       " ('cost', 2, 2, 0.10946545296872044),\n",
       " ('cost', 3, 1, 0.05473272648436022),\n",
       " ('critic', 2, 1, 0.07682709454675062),\n",
       " ('cross', 1, 1, 0.07682709454675062),\n",
       " ('data', 1, 1, 0.05473272648436022),\n",
       " ('data', 5, 1, 0.05473272648436022),\n",
       " ('dataset', 1, 1, 0.031129334620200573),\n",
       " ('dataset', 2, 6, 0.18677600772120342),\n",
       " ('dataset', 3, 1, 0.031129334620200573),\n",
       " ('dataset', 4, 1, 0.031129334620200573),\n",
       " ('dataset', 5, 1, 0.031129334620200573),\n",
       " ('date', 0, 1, 0.07682709454675062),\n",
       " ('de', 4, 1, 0.07682709454675062),\n",
       " ('deep', 0, 1, 0.043374659519969314),\n",
       " ('deep', 1, 1, 0.043374659519969314),\n",
       " ('deep', 5, 1, 0.043374659519969314),\n",
       " ('deeper', 1, 2, 0.15365418909350123),\n",
       " ('demonstr', 1, 1, 0.03617636442473069),\n",
       " ('demonstr', 3, 2, 0.07235272884946138),\n",
       " ('demonstr', 4, 1, 0.03617636442473069),\n",
       " ('demonstr', 5, 1, 0.03617636442473069),\n",
       " ('dens', 1, 3, 0.16419817945308063),\n",
       " ('dens', 4, 2, 0.10946545296872044),\n",
       " ('design', 1, 1, 0.05473272648436022),\n",
       " ('design', 2, 1, 0.05473272648436022),\n",
       " ('determinist', 0, 1, 0.07682709454675062),\n",
       " ('dev', 4, 2, 0.15365418909350123),\n",
       " ('develop', 2, 1, 0.07682709454675062),\n",
       " ('dimension', 1, 1, 0.07682709454675062),\n",
       " ('discret', 4, 1, 0.07682709454675062),\n",
       " ('disjoint', 4, 1, 0.07682709454675062),\n",
       " ('dl', 3, 1, 0.07682709454675062),\n",
       " ('dl19', 4, 2, 0.15365418909350123),\n",
       " ('document', 1, 7, 0.217905342341404),\n",
       " ('document', 2, 3, 0.09338800386060171),\n",
       " ('document', 3, 2, 0.062258669240401146),\n",
       " ('document', 4, 5, 0.15564667310100286),\n",
       " ('document', 5, 5, 0.15564667310100286),\n",
       " ('dori', 2, 4, 0.30730837818700246),\n",
       " ('drop', 2, 1, 0.07682709454675062),\n",
       " ('dual', 4, 2, 0.15365418909350123),\n",
       " ('due', 2, 2, 0.15365418909350123),\n",
       " ('effect', 0, 2, 0.062258669240401146),\n",
       " ('effect', 1, 1, 0.031129334620200573),\n",
       " ('effect', 2, 2, 0.062258669240401146),\n",
       " ('effect', 3, 5, 0.15564667310100286),\n",
       " ('effect', 4, 1, 0.031129334620200573),\n",
       " ('effici', 3, 4, 0.21893090593744088),\n",
       " ('effici', 4, 2, 0.10946545296872044),\n",
       " ('effort', 2, 1, 0.07682709454675062),\n",
       " ('ehi', 4, 5, 0.3841354727337531),\n",
       " ('elasticsearch', 1, 1, 0.07682709454675062),\n",
       " ('emb', 4, 1, 0.07682709454675062),\n",
       " ('embed', 1, 3, 0.13012397855990793),\n",
       " ('embed', 4, 5, 0.21687329759984655),\n",
       " ('embed', 5, 2, 0.08674931903993863),\n",
       " ('emerg', 5, 1, 0.07682709454675062),\n",
       " ('empir', 3, 1, 0.07682709454675062),\n",
       " ('employ', 1, 1, 0.07682709454675062),\n",
       " ('encod', 1, 3, 0.16419817945308063),\n",
       " ('encod', 4, 2, 0.10946545296872044),\n",
       " ('end', 4, 2, 0.15365418909350123),\n",
       " ('endpoint', 0, 1, 0.07682709454675062),\n",
       " ('engin', 1, 1, 0.07682709454675062),\n",
       " ('enhanc', 3, 1, 0.07682709454675062),\n",
       " ('ensur', 4, 1, 0.07682709454675062),\n",
       " ('estim', 5, 1, 0.07682709454675062),\n",
       " ('evalu', 2, 2, 0.08674931903993863),\n",
       " ('evalu', 3, 2, 0.08674931903993863),\n",
       " ('evalu', 5, 1, 0.043374659519969314),\n",
       " ('exampl', 4, 1, 0.07682709454675062),\n",
       " ('exist', 2, 1, 0.043374659519969314),\n",
       " ('exist', 3, 1, 0.043374659519969314),\n",
       " ('exist', 5, 1, 0.043374659519969314),\n",
       " ('expans', 1, 2, 0.10946545296872044),\n",
       " ('expans', 5, 4, 0.21893090593744088),\n",
       " ('experi', 1, 1, 0.07682709454675062),\n",
       " ('experiment', 0, 2, 0.10946545296872044),\n",
       " ('experiment', 3, 1, 0.05473272648436022),\n",
       " ('expert', 2, 2, 0.15365418909350123),\n",
       " ('extend', 2, 1, 0.07682709454675062),\n",
       " ('facto', 4, 1, 0.07682709454675062),\n",
       " ('factor', 3, 1, 0.07682709454675062),\n",
       " ('feedback', 5, 2, 0.15365418909350123),\n",
       " ('field', 2, 1, 0.07682709454675062),\n",
       " ('file', 4, 1, 0.07682709454675062),\n",
       " ('final', 1, 2, 0.15365418909350123),\n",
       " ('find', 3, 1, 0.05473272648436022),\n",
       " ('find', 4, 1, 0.05473272648436022),\n",
       " ('fine', 1, 1, 0.07682709454675062),\n",
       " ('first', 0, 1, 0.043374659519969314),\n",
       " ('first', 3, 1, 0.043374659519969314),\n",
       " ('first', 5, 1, 0.043374659519969314),\n",
       " ('fix', 1, 1, 0.07682709454675062),\n",
       " ('focu', 5, 1, 0.07682709454675062),\n",
       " ('foundat', 0, 2, 0.15365418909350123),\n",
       " ('framework', 1, 1, 0.043374659519969314),\n",
       " ('framework', 2, 1, 0.043374659519969314),\n",
       " ('framework', 3, 1, 0.043374659519969314),\n",
       " ('full', 1, 1, 0.07682709454675062),\n",
       " ('fulli', 0, 1, 0.07682709454675062),\n",
       " ('furthermor', 2, 1, 0.07682709454675062),\n",
       " ('futur', 0, 1, 0.07682709454675062),\n",
       " ('gap', 1, 1, 0.05473272648436022),\n",
       " ('gap', 5, 1, 0.05473272648436022),\n",
       " ('gener', 1, 1, 0.05473272648436022),\n",
       " ('gener', 5, 2, 0.10946545296872044),\n",
       " ('given', 4, 2, 0.15365418909350123),\n",
       " ('gov02', 5, 1, 0.07682709454675062),\n",
       " ('gpt', 0, 2, 0.10946545296872044),\n",
       " ('gpt', 2, 1, 0.05473272648436022),\n",
       " ('handl', 2, 2, 0.15365418909350123),\n",
       " ('hidden', 0, 1, 0.07682709454675062),\n",
       " ('hierarch', 4, 1, 0.07682709454675062),\n",
       " ('high', 0, 1, 0.043374659519969314),\n",
       " ('high', 2, 1, 0.043374659519969314),\n",
       " ('high', 3, 3, 0.13012397855990793),\n",
       " ('higher', 5, 1, 0.07682709454675062),\n",
       " ('highlight', 2, 1, 0.07682709454675062),\n",
       " ('hope', 0, 1, 0.07682709454675062),\n",
       " ('howev', 5, 1, 0.07682709454675062),\n",
       " ('human', 2, 1, 0.07682709454675062),\n",
       " ('identifi', 3, 1, 0.07682709454675062),\n",
       " ('ignor', 5, 1, 0.07682709454675062),\n",
       " ('ill', 4, 1, 0.07682709454675062),\n",
       " ('impress', 3, 1, 0.07682709454675062),\n",
       " ('improv', 1, 1, 0.043374659519969314),\n",
       " ('improv', 3, 1, 0.043374659519969314),\n",
       " ('improv', 5, 1, 0.043374659519969314),\n",
       " ('includ', 4, 1, 0.07682709454675062),\n",
       " ('incur', 3, 1, 0.07682709454675062),\n",
       " ('index', 1, 1, 0.05473272648436022),\n",
       " ('index', 4, 2, 0.10946545296872044),\n",
       " ('indic', 3, 1, 0.07682709454675062),\n",
       " ('industri', 4, 2, 0.15365418909350123),\n",
       " ('infer', 3, 1, 0.07682709454675062),\n",
       " ('inform', 0, 1, 0.05473272648436022),\n",
       " ('inform', 5, 1, 0.05473272648436022),\n",
       " ('inher', 3, 1, 0.07682709454675062),\n",
       " ('input', 1, 1, 0.07682709454675062),\n",
       " ('interact', 1, 1, 0.05473272648436022),\n",
       " ('interact', 5, 2, 0.10946545296872044),\n",
       " ('introduc', 2, 1, 0.05473272648436022),\n",
       " ('introduc', 4, 1, 0.05473272648436022),\n",
       " ('invert', 4, 1, 0.07682709454675062),\n",
       " ('ir', 5, 2, 0.15365418909350123),\n",
       " ('ivf', 4, 1, 0.07682709454675062),\n",
       " ('jointli', 4, 1, 0.07682709454675062),\n",
       " ('kind', 3, 1, 0.07682709454675062),\n",
       " ('known', 1, 1, 0.07682709454675062),\n",
       " ('labor', 2, 1, 0.07682709454675062),\n",
       " ('languag', 0, 1, 0.043374659519969314),\n",
       " ('languag', 2, 1, 0.043374659519969314),\n",
       " ('languag', 3, 1, 0.043374659519969314),\n",
       " ('larg', 0, 1, 0.03617636442473069),\n",
       " ('larg', 1, 1, 0.03617636442473069),\n",
       " ('larg', 2, 1, 0.03617636442473069),\n",
       " ('larg', 3, 1, 0.03617636442473069),\n",
       " ('latenc', 3, 1, 0.07682709454675062),\n",
       " ('latent', 5, 2, 0.15365418909350123),\n",
       " ('lead', 4, 1, 0.07682709454675062),\n",
       " ('learn', 0, 1, 0.03617636442473069),\n",
       " ('learn', 1, 2, 0.07235272884946138),\n",
       " ('learn', 4, 5, 0.18088182212365345),\n",
       " ('learn', 5, 2, 0.07235272884946138),\n",
       " ('length', 1, 1, 0.07682709454675062),\n",
       " ('lengthi', 1, 1, 0.07682709454675062),\n",
       " ('level', 2, 2, 0.15365418909350123),\n",
       " ('leverag', 1, 1, 0.05473272648436022),\n",
       " ('leverag', 5, 1, 0.05473272648436022),\n",
       " ('like', 3, 1, 0.05473272648436022),\n",
       " ('like', 4, 1, 0.05473272648436022),\n",
       " ('limit', 1, 1, 0.05473272648436022),\n",
       " ('limit', 2, 1, 0.05473272648436022),\n",
       " ('listwis', 0, 1, 0.05473272648436022),\n",
       " ('listwis', 3, 1, 0.05473272648436022),\n",
       " ('llm', 0, 3, 0.13012397855990793),\n",
       " ('llm', 2, 2, 0.08674931903993863),\n",
       " ('llm', 3, 5, 0.21687329759984655),\n",
       " ('low', 1, 1, 0.07682709454675062),\n",
       " ('mae', 2, 4, 0.30730837818700246),\n",
       " ('mani', 5, 1, 0.07682709454675062),\n",
       " ('map', 5, 1, 0.07682709454675062),\n",
       " ('marco', 4, 2, 0.10946545296872044),\n",
       " ('marco', 5, 1, 0.05473272648436022),\n",
       " ('match', 1, 2, 0.10946545296872044),\n",
       " ('match', 5, 1, 0.05473272648436022),\n",
       " ('maximum', 1, 1, 0.07682709454675062),\n",
       " ('method', 2, 1, 0.043374659519969314),\n",
       " ('method', 3, 1, 0.043374659519969314),\n",
       " ('method', 4, 1, 0.043374659519969314),\n",
       " ('might', 4, 1, 0.07682709454675062),\n",
       " ('model', 0, 3, 0.08209908972654031),\n",
       " ('model', 1, 7, 0.19156454269526077),\n",
       " ('model', 2, 1, 0.02736636324218011),\n",
       " ('model', 3, 2, 0.05473272648436022),\n",
       " ('model', 4, 1, 0.02736636324218011),\n",
       " ('model', 5, 11, 0.3010299956639812),\n",
       " ('modern', 0, 1, 0.07682709454675062),\n",
       " ('mostli', 0, 1, 0.07682709454675062),\n",
       " ('mrr', 4, 1, 0.07682709454675062),\n",
       " ('ms', 4, 2, 0.10946545296872044),\n",
       " ('ms', 5, 1, 0.05473272648436022),\n",
       " ('much', 0, 1, 0.07682709454675062),\n",
       " ('multi', 2, 2, 0.15365418909350123),\n",
       " ('multifacet', 2, 2, 0.15365418909350123),\n",
       " ('natur', 2, 1, 0.07682709454675062),\n",
       " ('ndcg', 4, 1, 0.07682709454675062),\n",
       " ('nearest', 4, 1, 0.07682709454675062),\n",
       " ('need', 2, 1, 0.07682709454675062),\n",
       " ('neighbor', 4, 1, 0.07682709454675062),\n",
       " ('neural', 5, 3, 0.23048128364025183),\n",
       " ('non', 0, 1, 0.07682709454675062),\n",
       " ('notabl', 2, 1, 0.07682709454675062),\n",
       " ('notion', 4, 1, 0.07682709454675062),\n",
       " ('novel', 2, 1, 0.05473272648436022),\n",
       " ('novel', 3, 1, 0.05473272648436022),\n",
       " ('number', 3, 1, 0.07682709454675062),\n",
       " ('observ', 2, 1, 0.07682709454675062),\n",
       " ('obtain', 4, 1, 0.07682709454675062),\n",
       " ('off', 3, 1, 0.07682709454675062),\n",
       " ('often', 5, 1, 0.07682709454675062),\n",
       " ('ohsum', 1, 1, 0.07682709454675062),\n",
       " ('opaqu', 0, 1, 0.07682709454675062),\n",
       " ('open', 0, 1, 0.07682709454675062),\n",
       " ('optim', 4, 1, 0.07682709454675062),\n",
       " ('other', 3, 1, 0.07682709454675062),\n",
       " ('outcom', 0, 1, 0.07682709454675062),\n",
       " ('outperform', 4, 1, 0.05473272648436022),\n",
       " ('outperform', 5, 1, 0.05473272648436022),\n",
       " ('overhead', 3, 1, 0.07682709454675062),\n",
       " ('pair', 5, 1, 0.07682709454675062),\n",
       " ('pairwis', 3, 2, 0.15365418909350123),\n",
       " ('paramet', 0, 1, 0.07682709454675062),\n",
       " ('passag', 5, 1, 0.07682709454675062),\n",
       " ('path', 4, 1, 0.07682709454675062),\n",
       " ('perform', 0, 1, 0.031129334620200573),\n",
       " ('perform', 1, 2, 0.062258669240401146),\n",
       " ('perform', 2, 2, 0.062258669240401146),\n",
       " ('perform', 4, 2, 0.062258669240401146),\n",
       " ('perform', 5, 1, 0.031129334620200573),\n",
       " ('phrase', 1, 2, 0.15365418909350123),\n",
       " ('pipelin', 1, 1, 0.07682709454675062),\n",
       " ('pointwis', 3, 2, 0.15365418909350123),\n",
       " ('poor', 3, 1, 0.07682709454675062),\n",
       " ('posit', 4, 1, 0.07682709454675062),\n",
       " ('present', 0, 1, 0.07682709454675062),\n",
       " ('primarili', 2, 1, 0.07682709454675062),\n",
       " ('problem', 4, 1, 0.07682709454675062),\n",
       " ('procedur', 3, 1, 0.07682709454675062),\n",
       " ('process', 4, 1, 0.07682709454675062),\n",
       " ('produc', 1, 2, 0.10946545296872044),\n",
       " ('produc', 2, 1, 0.05473272648436022),\n",
       " ('prompt', 3, 3, 0.23048128364025183),\n",
       " ('propos', 1, 1, 0.031129334620200573),\n",
       " ('propos', 2, 1, 0.031129334620200573),\n",
       " ('propos', 3, 2, 0.062258669240401146),\n",
       " ('propos', 4, 1, 0.031129334620200573),\n",
       " ('propos', 5, 3, 0.09338800386060171),\n",
       " ('proprietari', 0, 1, 0.07682709454675062),\n",
       " ('provid', 0, 1, 0.07682709454675062),\n",
       " ('pseudo', 5, 1, 0.07682709454675062),\n",
       " ('qe', 5, 4, 0.30730837818700246),\n",
       " ('qualiti', 0, 1, 0.05473272648436022),\n",
       " ('qualiti', 2, 1, 0.05473272648436022),\n",
       " ('queri', 1, 9, 0.32558727982257624),\n",
       " ('queri', 2, 9, 0.32558727982257624),\n",
       " ('queri', 4, 5, 0.18088182212365345),\n",
       " ('queri', 5, 5, 0.18088182212365345),\n",
       " ('rank', 1, 1, 0.031129334620200573),\n",
       " ('rank', 2, 1, 0.031129334620200573),\n",
       " ('rank', 3, 7, 0.217905342341404),\n",
       " ('rank', 4, 1, 0.031129334620200573),\n",
       " ('rank', 5, 2, 0.062258669240401146),\n",
       " ('rankvicuna', 0, 1, 0.07682709454675062),\n",
       " ('recent', 2, 1, 0.05473272648436022),\n",
       " ('recent', 5, 1, 0.05473272648436022),\n",
       " ('recogn', 2, 1, 0.07682709454675062),\n",
       " ('record', 1, 1, 0.07682709454675062),\n",
       " ('reduc', 1, 1, 0.05473272648436022),\n",
       " ('reduc', 3, 2, 0.10946545296872044),\n",
       " ('reduct', 2, 1, 0.07682709454675062),\n",
       " ('relev', 1, 1, 0.03617636442473069),\n",
       " ('relev', 2, 3, 0.10852909327419206),\n",
       " ('relev', 4, 1, 0.03617636442473069),\n",
       " ('relev', 5, 3, 0.10852909327419206),\n",
       " ('remain', 0, 1, 0.07682709454675062),\n",
       " ('repres', 1, 1, 0.05473272648436022),\n",
       " ('repres', 2, 1, 0.05473272648436022),\n",
       " ('represent', 1, 3, 0.23048128364025183),\n",
       " ('reproduc', 0, 1, 0.07682709454675062),\n",
       " ('requir', 2, 2, 0.15365418909350123),\n",
       " ('rerank', 0, 5, 0.3841354727337531),\n",
       " ('research', 0, 2, 0.08674931903993863),\n",
       " ('research', 2, 3, 0.13012397855990793),\n",
       " ('research', 5, 2, 0.08674931903993863),\n",
       " ('resourc', 2, 1, 0.07682709454675062),\n",
       " ('result', 0, 2, 0.062258669240401146),\n",
       " ('result', 1, 3, 0.09338800386060171),\n",
       " ('result', 2, 1, 0.031129334620200573),\n",
       " ('result', 3, 1, 0.031129334620200573),\n",
       " ('result', 5, 1, 0.031129334620200573),\n",
       " ('retain', 3, 1, 0.07682709454675062),\n",
       " ('retriev', 0, 1, 0.031129334620200573),\n",
       " ('retriev', 1, 3, 0.09338800386060171),\n",
       " ('retriev', 2, 3, 0.09338800386060171),\n",
       " ('retriev', 4, 2, 0.062258669240401146),\n",
       " ('retriev', 5, 1, 0.031129334620200573),\n",
       " ('richer', 1, 1, 0.07682709454675062),\n",
       " ('robust', 5, 1, 0.07682709454675062),\n",
       " ('sbert', 1, 1, 0.07682709454675062),\n",
       " ('scalabl', 2, 1, 0.07682709454675062),\n",
       " ('scienc', 2, 1, 0.07682709454675062),\n",
       " ('scientif', 2, 4, 0.30730837818700246),\n",
       " ('score', 2, 1, 0.05473272648436022),\n",
       " ('score', 3, 1, 0.05473272648436022),\n",
       " ('search', 1, 1, 0.05473272648436022),\n",
       " ('search', 4, 2, 0.10946545296872044),\n",
       " ('self', 1, 1, 0.07682709454675062),\n",
       " ('semant', 1, 2, 0.08674931903993863),\n",
       " ('semant', 4, 1, 0.043374659519969314),\n",
       " ('semant', 5, 1, 0.043374659519969314),\n",
       " ('sentenc', 1, 1, 0.07682709454675062),\n",
       " ('separ', 1, 2, 0.15365418909350123),\n",
       " ('set', 0, 1, 0.05473272648436022),\n",
       " ('set', 4, 2, 0.10946545296872044),\n",
       " ('setwis', 3, 1, 0.07682709454675062),\n",
       " ('sever', 4, 1, 0.07682709454675062),\n",
       " ('shaki', 0, 1, 0.07682709454675062),\n",
       " ('short', 1, 1, 0.07682709454675062),\n",
       " ('shortcom', 0, 1, 0.07682709454675062),\n",
       " ('shot', 0, 2, 0.10946545296872044),\n",
       " ('shot', 3, 6, 0.32839635890616126),\n",
       " ('show', 0, 1, 0.05473272648436022),\n",
       " ('show', 5, 1, 0.05473272648436022),\n",
       " ('signific', 0, 1, 0.05473272648436022),\n",
       " ('signific', 2, 1, 0.05473272648436022),\n",
       " ('significantli', 3, 1, 0.07682709454675062),\n",
       " ('similar', 4, 1, 0.05473272648436022),\n",
       " ('similar', 5, 1, 0.05473272648436022),\n",
       " ('size', 1, 1, 0.05473272648436022),\n",
       " ('size', 3, 1, 0.05473272648436022),\n",
       " ('slightli', 0, 1, 0.07682709454675062),\n",
       " ('smaller', 0, 1, 0.07682709454675062),\n",
       " ('sota', 4, 1, 0.07682709454675062),\n",
       " ('sourc', 0, 1, 0.07682709454675062),\n",
       " ('space', 1, 2, 0.10946545296872044),\n",
       " ('space', 5, 2, 0.10946545296872044),\n",
       " ('specif', 1, 1, 0.07682709454675062),\n",
       " ('stabl', 4, 1, 0.07682709454675062),\n",
       " ('stage', 4, 2, 0.15365418909350123),\n",
       " ('standard', 4, 3, 0.16419817945308063),\n",
       " ('standard', 5, 1, 0.05473272648436022),\n",
       " ('state', 4, 1, 0.05473272648436022),\n",
       " ('state', 5, 1, 0.05473272648436022),\n",
       " ('structur', 2, 1, 0.05473272648436022),\n",
       " ('structur', 4, 3, 0.16419817945308063),\n",
       " ('studi', 1, 2, 0.10946545296872044),\n",
       " ('studi', 3, 1, 0.05473272648436022),\n",
       " ('style', 4, 1, 0.07682709454675062),\n",
       " ('sub', 2, 1, 0.07682709454675062),\n",
       " ('suboptim', 4, 1, 0.07682709454675062),\n",
       " ('success', 0, 1, 0.07682709454675062),\n",
       " ('suffer', 3, 1, 0.07682709454675062),\n",
       " ('suit', 4, 1, 0.07682709454675062),\n",
       " ('summar', 1, 1, 0.07682709454675062),\n",
       " ('superior', 3, 1, 0.07682709454675062),\n",
       " ('task', 2, 3, 0.16419817945308063),\n",
       " ('task', 3, 1, 0.05473272648436022),\n",
       " ('techniqu', 4, 1, 0.07682709454675062),\n",
       " ('term', 5, 1, 0.07682709454675062),\n",
       " ('test', 2, 1, 0.043374659519969314),\n",
       " ('test', 3, 1, 0.043374659519969314),\n",
       " ('test', 5, 1, 0.043374659519969314),\n",
       " ('text', 1, 4, 0.30730837818700246),\n",
       " ('thoroughli', 3, 1, 0.07682709454675062),\n",
       " ('threaten', 0, 1, 0.07682709454675062),\n",
       " ('three', 5, 1, 0.07682709454675062),\n",
       " ('tier', 2, 1, 0.07682709454675062),\n",
       " ('time', 5, 1, 0.07682709454675062),\n",
       " ('token', 1, 1, 0.05473272648436022),\n",
       " ('token', 3, 2, 0.10946545296872044),\n",
       " ('track', 0, 1, 0.07682709454675062),\n",
       " ('trade', 3, 1, 0.07682709454675062),\n",
       " ('tradit', 2, 1, 0.05473272648436022),\n",
       " ('tradit', 5, 2, 0.10946545296872044),\n",
       " ('train', 4, 1, 0.05473272648436022),\n",
       " ('train', 5, 1, 0.05473272648436022),\n",
       " ('transform', 1, 3, 0.23048128364025183),\n",
       " ('trec', 0, 1, 0.031129334620200573),\n",
       " ('trec', 1, 1, 0.031129334620200573),\n",
       " ('trec', 3, 1, 0.031129334620200573),\n",
       " ('trec', 4, 2, 0.062258669240401146),\n",
       " ('trec', 5, 1, 0.031129334620200573),\n",
       " ('tree', 4, 3, 0.23048128364025183),\n",
       " ('tune', 1, 1, 0.07682709454675062),\n",
       " ('two', 1, 1, 0.05473272648436022),\n",
       " ('two', 4, 2, 0.10946545296872044),\n",
       " ('understand', 1, 2, 0.15365418909350123),\n",
       " ('us', 3, 1, 0.07682709454675062),\n",
       " ('use', 1, 2, 0.062258669240401146),\n",
       " ('use', 2, 1, 0.031129334620200573),\n",
       " ('use', 3, 1, 0.031129334620200573),\n",
       " ('use', 4, 2, 0.062258669240401146),\n",
       " ('use', 5, 3, 0.09338800386060171),\n",
       " ('user', 2, 1, 0.07682709454675062),\n",
       " ('valid', 2, 1, 0.07682709454675062),\n",
       " ('variat', 5, 1, 0.07682709454675062),\n",
       " ('vector', 1, 5, 0.3841354727337531),\n",
       " ('verac', 0, 1, 0.07682709454675062),\n",
       " ('versa', 4, 1, 0.07682709454675062),\n",
       " ('vice', 4, 1, 0.07682709454675062),\n",
       " ('web', 4, 1, 0.07682709454675062),\n",
       " ('well', 1, 1, 0.07682709454675062),\n",
       " ('within', 2, 1, 0.05473272648436022),\n",
       " ('within', 3, 1, 0.05473272648436022),\n",
       " ('without', 2, 2, 0.15365418909350123),\n",
       " ('work', 0, 2, 0.10946545296872044),\n",
       " ('work', 4, 1, 0.05473272648436022),\n",
       " ('year', 5, 1, 0.07682709454675062),\n",
       " ('yield', 0, 1, 0.05473272648436022),\n",
       " ('yield', 1, 1, 0.05473272648436022),\n",
       " ('zero', 0, 2, 0.10946545296872044),\n",
       " ('zero', 3, 6, 0.32839635890616126)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Docs:\n",
    "\n",
    "    def __init__(self,Lancaster=True,split=False):\n",
    "\n",
    "        docs = []\n",
    "        self.maxfreq = 0\n",
    "        MotsVides = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "        self.files = [\"TP2data/D1.txt\",\"TP2data/D2.txt\",\"TP2data/D3.txt\",\"TP2data/D4.txt\",\"TP2data/D5.txt\",\"TP2data/D6.txt\"]\n",
    "        file = \"\"\n",
    "        my_dict = {}\n",
    "        for i in range(len(self.files)):\n",
    "            file = open(self.files[i]).read()\n",
    "            file = file.replace(\"\\n\",\"\")\n",
    "\n",
    "            if split :\n",
    "                TermesNormalisation = file.split()\n",
    "            else :\n",
    "\n",
    "                ExpReg = nltk.RegexpTokenizer('(?:[A-Z]\\.)+|\\w+') # \\d : équivalent à [0-9] >>> \n",
    "                Termes = ExpReg.tokenize(file) \n",
    "\n",
    "            if Lancaster :\n",
    "                TermesSansMotsVides = [terme for terme in Termes if terme.lower() not in MotsVides]\n",
    "                Lancaster = nltk.LancasterStemmer()\n",
    "                TermesNormalisation = [Lancaster.stem(terme) for terme in TermesSansMotsVides]\n",
    "            else :\n",
    "                TermesSansMotsVides = [terme for terme in Termes if terme.lower() not in MotsVides]\n",
    "                porter = nltk.PorterStemmer()\n",
    "                TermesNormalisation = [porter.stem(terme) for terme in TermesSansMotsVides]\n",
    "\n",
    "\n",
    "            for term in TermesNormalisation:\n",
    "                \n",
    "                if (term,i) in my_dict:\n",
    "                    my_dict[(term,i)] += 1\n",
    "                else:\n",
    "                    my_dict[(term,i)] = 1\n",
    "\n",
    "        self.dict = my_dict\n",
    "\n",
    "        for keys in self.dict.keys():\n",
    "            if keys[1] not in docs:\n",
    "                docs.append(keys[1])\n",
    "            if self.dict[keys] > self.maxfreq:\n",
    "                self.maxfreq = self.dict[keys]\n",
    "        print(self.maxfreq)\n",
    "        self.N = len(docs)\n",
    "    \n",
    "    def rebuild(self,Lancaster=True,split=False):\n",
    "        docs = []\n",
    "        self.maxfreq = 0\n",
    "        MotsVides = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "        \n",
    "        file = \"\"\n",
    "        my_dict = {}\n",
    "        for i in range(len(self.files)):\n",
    "            file = open(self.files[i]).read()\n",
    "            file = file.replace(\"\\n\",\"\")\n",
    "\n",
    "\n",
    "            if not split :\n",
    "                Termes = file.split()\n",
    "            else :\n",
    "                ExpReg = nltk.RegexpTokenizer('(?:[A-Z]\\.)+|\\w+|\\.{3}') # \\d : équivalent à [0-9] >>> \n",
    "                Termes = ExpReg.tokenize(file) \n",
    "            \n",
    "\n",
    "            if Lancaster :\n",
    "                print('lancaster')\n",
    "                TermesSansMotsVides = [terme for terme in Termes if terme.lower() not in MotsVides]\n",
    "                Lancaster = nltk.LancasterStemmer()\n",
    "                TermesNormalisation = [Lancaster.stem(terme) for terme in TermesSansMotsVides]\n",
    "            else :\n",
    "                print('porter')\n",
    "                TermesSansMotsVides = [terme for terme in Termes if terme.lower() not in MotsVides]\n",
    "                porter = nltk.PorterStemmer()\n",
    "                TermesNormalisation = [porter.stem(terme) for terme in TermesSansMotsVides]\n",
    "\n",
    "            for term in TermesNormalisation:\n",
    "                \n",
    "                if (term,i) in my_dict:\n",
    "                    my_dict[(term,i)] += 1\n",
    "                else:\n",
    "                    my_dict[(term,i)] = 1\n",
    "\n",
    "        self.dict = my_dict\n",
    "\n",
    "        for keys in self.dict.keys():\n",
    "            if keys[1] not in docs:\n",
    "                docs.append(keys[1])\n",
    "            if self.dict[keys] > self.maxfreq:\n",
    "                self.maxfreq = self.dict[keys]\n",
    "\n",
    "        self.N = len(docs)\n",
    "        self.DictWeight()\n",
    "\n",
    "    def calcWeight(self,word,doc):\n",
    "\n",
    "        inDocs = []\n",
    "\n",
    "        for keys in self.dict.keys():\n",
    "            if keys[0] == word:\n",
    "                if keys[1] not in inDocs:\n",
    "                    inDocs.append(keys[1])\n",
    "\n",
    "        # nombre de documents contenant le mot\n",
    "        Ni = len(inDocs)\n",
    "\n",
    "        try:\n",
    "            tf = self.dict[(word,doc)]/self.maxfreq\n",
    "        except:\n",
    "            tf = 0\n",
    "            \n",
    "        #idf = math.log10((N/Ni)+1)\n",
    "        try:\n",
    "            idf = math.log10((self.N/Ni)+1)\n",
    "        except:\n",
    "            idf = 0\n",
    "\n",
    "        return(tf*idf)\n",
    "\n",
    "    def DictWeight(self):\n",
    "        self.TDFP = [(word,doc,self.dict[(word,doc)],self.calcWeight(word,doc)) for word,doc in self.dict.keys()]\n",
    "        self.DTFP = [(doc,word,freq,weight) for word,doc,freq,weight in self.TDFP]\n",
    "        self.TDFP = sorted(self.TDFP, key=lambda x: x[0])\n",
    "\n",
    "        \n",
    "d = Docs(Lancaster=False)\n",
    "\n",
    "d.DictWeight()\n",
    "\n",
    "d.TDFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lancaster\n",
      "lancaster\n",
      "lancaster\n",
      "lancaster\n",
      "lancaster\n",
      "lancaster\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\mekki\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\tkinter\\__init__.py\", line 1948, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\mekki\\AppData\\Local\\Temp\\ipykernel_6704\\2791770733.py\", line 27, in on_token_change\n",
      "    search()\n",
      "  File \"C:\\Users\\mekki\\AppData\\Local\\Temp\\ipykernel_6704\\2791770733.py\", line 7, in search\n",
      "    table.delete(*table.get_children())\n",
      "                  ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\mekki\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\tkinter\\ttk.py\", line 1195, in get_children\n",
      "    self.tk.call(self._w, \"children\", item or '') or ())\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "_tkinter.TclError: invalid command name \".!frame.!treeview\"\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "\n",
    "def search():\n",
    "\n",
    "    text = query_text.get()\n",
    "    table.delete(*table.get_children())\n",
    "\n",
    "    if index_var.get() == 0:\n",
    "        data = d.TDFP\n",
    "    else:\n",
    "        data = d.DTFP\n",
    "\n",
    "    for terme in data:\n",
    "\n",
    "        if type(terme[0]) is str:\n",
    "            if text.lower() in terme[0].lower():\n",
    "                table.insert(\"\", \"end\", values=[terme[0],terme[1],terme[2],terme[3]])\n",
    "        else:\n",
    "            if text.lower() in terme[1].lower():\n",
    "                table.insert(\"\", \"end\", values=[terme[0],terme[1],terme[2],terme[3]])\n",
    "    # Add your search and processing logic here\n",
    "    pass\n",
    "\n",
    "def on_token_change(*args):\n",
    "    d.rebuild(Lancaster=stemming.get(),split=token.get())\n",
    "    search()\n",
    "\n",
    "def on_index_change(*args):\n",
    "    search()\n",
    "\n",
    "# Create the main application window\n",
    "root = tk.Tk()\n",
    "root.title(\"Text Processing Application\")\n",
    "\n",
    "# Search Query Text Box and Search Button\n",
    "query_label = tk.Label(root, text=\"Search Query:\")\n",
    "query_label.grid(row=0, column=0)\n",
    "query_text = tk.Entry(root, width=40)\n",
    "query_text.grid(row=0, column=1)\n",
    "search_button = tk.Button(root, text=\"Search\", command=search)\n",
    "search_button.grid(row=0, column=2)\n",
    "\n",
    "# Border around \"Processing\" section\n",
    "processing_label_frame = ttk.LabelFrame(root, text=\"Processing\")\n",
    "processing_label_frame.grid(row=1, column=2, padx=10, pady=10)\n",
    "\n",
    "# Radio buttons for Processing\n",
    "stemming = tk.IntVar()\n",
    "stemming.trace(\"w\", on_token_change)\n",
    "\n",
    "token = tk.IntVar()\n",
    "token.trace(\"w\", on_token_change)\n",
    "\n",
    "tokenization_radiobutton = tk.Checkbutton(processing_label_frame, text=\"Tokenization\", variable=token)\n",
    "porter_stemmer_radiobutton = tk.Checkbutton(processing_label_frame, text=\"Lancaster Stemmer\", variable=stemming)\n",
    "porter_stemmer_radiobutton.select()\n",
    "tokenization_radiobutton.grid(row=0, column=0)\n",
    "porter_stemmer_radiobutton.grid(row=1, column=0)\n",
    "\n",
    "# Border around \"Index\" section\n",
    "index_label_frame = ttk.LabelFrame(root, text=\"Index\")\n",
    "index_label_frame.grid(row=1, column=0, padx=10, pady=10)\n",
    "\n",
    "# Radio buttons for Index\n",
    "\n",
    "index_var = tk.IntVar()\n",
    "index_var.trace(\"w\", on_index_change)\n",
    "\n",
    "docs_per_term_radiobutton = tk.Radiobutton(index_label_frame, text=\"DOCS per TERM\", variable=index_var, value=0)\n",
    "terms_per_doc_radiobutton = tk.Radiobutton(index_label_frame, text=\"TERMS per DOC\", variable=index_var, value=1)\n",
    "docs_per_term_radiobutton.grid(row=1, column=0)\n",
    "terms_per_doc_radiobutton.grid(row=2, column=0)\n",
    "\n",
    "# Table to display data\n",
    "table_frame = ttk.Frame(root)\n",
    "table_frame.grid(row=2, column=0, columnspan=3, pady=10)\n",
    "table = ttk.Treeview(table_frame, columns=(\"1\", \"2\", \"3\", \"4\"))\n",
    "table.heading(\"#1\", text=\"terme\")\n",
    "table.heading(\"#2\", text=\"document\")\n",
    "table.heading(\"#3\", text=\"freq\")\n",
    "table.heading(\"#4\", text=\"Score\")\n",
    "table['show'] = 'headings'\n",
    "# Vertical scrollbar for the table\n",
    "table_scrollbar = ttk.Scrollbar(table_frame, orient=\"vertical\", command=table.yview)\n",
    "table.configure(yscrollcommand=table_scrollbar.set)\n",
    "\n",
    "# Grid layout for the table and scrollbar\n",
    "table.grid(row=0, column=0, sticky=\"nsew\")\n",
    "table_scrollbar.grid(row=0, column=1, sticky=\"ns\")\n",
    "\n",
    "\n",
    "# Make the table resizable\n",
    "table_frame.grid_rowconfigure(0, weight=1)\n",
    "table_frame.grid_columnconfigure(0, weight=1)\n",
    "\n",
    "\n",
    "for dat in d.TDFP:\n",
    "    table.insert(\"\", \"end\", values=[dat[0],dat[1],dat[2],dat[3]])\n",
    "\n",
    "\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
