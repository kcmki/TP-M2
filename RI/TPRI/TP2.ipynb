{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import nltk\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 0, 1, 0.05376692341046299),\n",
       " ('(1)', 0, 1, 0.05376692341046299),\n",
       " ('(2)', 0, 1, 0.05376692341046299),\n",
       " ('(GNNs).', 0, 1, 0.05376692341046299),\n",
       " ('(JNSKR).', 3, 1, 0.05376692341046299),\n",
       " ('(KG)', 0, 1, 0.03670163497843557),\n",
       " ('(KG)', 3, 1, 0.03670163497843557),\n",
       " ('(KGIN).', 0, 1, 0.05376692341046299),\n",
       " ('(NS)', 3, 1, 0.05376692341046299),\n",
       " ('(TGSRec)', 1, 1, 0.05376692341046299),\n",
       " ('(about', 3, 1, 0.05376692341046299),\n",
       " ('(e.g.,', 2, 1, 0.03670163497843557),\n",
       " ('(e.g.,', 3, 1, 0.03670163497843557),\n",
       " ('(i.e.,', 0, 1, 0.05376692341046299),\n",
       " ('(including', 3, 1, 0.05376692341046299),\n",
       " ('0.70,', 2, 1, 0.05376692341046299),\n",
       " ('0.87,', 2, 1, 0.05376692341046299),\n",
       " ('0.95', 2, 1, 0.05376692341046299),\n",
       " ('20', 3, 1, 0.05376692341046299),\n",
       " ('22.1%', 1, 1, 0.05376692341046299),\n",
       " ('22.5%', 1, 1, 0.05376692341046299),\n",
       " ('A', 0, 1, 0.05376692341046299),\n",
       " ('By', 2, 1, 0.05376692341046299),\n",
       " ('CKAN', 0, 1, 0.05376692341046299),\n",
       " ('Collaborative', 1, 1, 0.05376692341046299),\n",
       " ('Empirical', 1, 1, 0.05376692341046299),\n",
       " ('Evaluation', 2, 1, 0.05376692341046299),\n",
       " ('Existing', 1, 1, 0.05376692341046299),\n",
       " ('Experimental', 0, 1, 0.03670163497843557),\n",
       " ('Experimental', 3, 1, 0.03670163497843557),\n",
       " ('F1', 2, 1, 0.05376692341046299),\n",
       " ('Firstly,', 1, 1, 0.05376692341046299),\n",
       " ('Further', 0, 1, 0.05376692341046299),\n",
       " ('Furthermore,', 0, 1, 0.05376692341046299),\n",
       " ('GNN,', 0, 1, 0.05376692341046299),\n",
       " ('GNN-based', 0, 1, 0.05376692341046299),\n",
       " ('Graph', 1, 1, 0.05376692341046299),\n",
       " ('Graph-based', 0, 1, 0.05376692341046299),\n",
       " ('However,', 0, 1, 0.02830590656112264),\n",
       " ('However,', 1, 1, 0.02830590656112264),\n",
       " ('However,', 3, 1, 0.02830590656112264),\n",
       " ('In', 1, 1, 0.03670163497843557),\n",
       " ('In', 3, 1, 0.03670163497843557),\n",
       " ('Intent', 0, 1, 0.05376692341046299),\n",
       " ('JNSKR', 3, 3, 0.16130077023138897),\n",
       " ('Jointly', 3, 1, 0.05376692341046299),\n",
       " ('KG', 0, 1, 0.03670163497843557),\n",
       " ('KG', 3, 2, 0.07340326995687114),\n",
       " ('KG.', 3, 1, 0.05376692341046299),\n",
       " ('KGAT', 0, 1, 0.05376692341046299),\n",
       " ('KGAT),', 3, 1, 0.05376692341046299),\n",
       " ('KGAT.', 3, 1, 0.05376692341046299),\n",
       " ('KGIN', 0, 2, 0.10753384682092598),\n",
       " ('KnowEdu,', 2, 1, 0.05376692341046299),\n",
       " ('Knowledge', 0, 2, 0.07340326995687114),\n",
       " ('Knowledge', 3, 2, 0.07340326995687114),\n",
       " ('MRR,', 1, 1, 0.05376692341046299),\n",
       " ('More', 2, 1, 0.05376692341046299),\n",
       " ('Motivated', 2, 1, 0.05376692341046299),\n",
       " ('NS', 3, 2, 0.10753384682092598),\n",
       " ('Negative', 3, 1, 0.05376692341046299),\n",
       " ('Network', 0, 1, 0.05376692341046299),\n",
       " ('Non-Sampling', 3, 1, 0.05376692341046299),\n",
       " ('Recall@10', 1, 1, 0.05376692341046299),\n",
       " ('Recommendation', 3, 1, 0.05376692341046299),\n",
       " ('Recommendation~(SR)', 1, 1, 0.05376692341046299),\n",
       " ('Recommender', 1, 1, 0.05376692341046299),\n",
       " ('Remarkably,', 3, 1, 0.05376692341046299),\n",
       " ('RippleNet', 3, 1, 0.05376692341046299),\n",
       " ('Sampling', 3, 1, 0.05376692341046299),\n",
       " ('Secondly,', 1, 1, 0.05376692341046299),\n",
       " ('Sequential', 1, 2, 0.10753384682092598),\n",
       " ('Since', 3, 1, 0.05376692341046299),\n",
       " ('Specifically,', 3, 1, 0.05376692341046299),\n",
       " ('TCT', 1, 3, 0.16130077023138897),\n",
       " ('TGSRec,', 1, 1, 0.05376692341046299),\n",
       " ('Technically,', 0, 1, 0.05376692341046299),\n",
       " ('Temporal', 1, 2, 0.10753384682092598),\n",
       " ('The', 3, 1, 0.05376692341046299),\n",
       " ('Therefore,', 1, 1, 0.05376692341046299),\n",
       " ('This', 0, 1, 0.05376692341046299),\n",
       " ('Through', 3, 1, 0.05376692341046299),\n",
       " ('Transformer', 1, 1, 0.05376692341046299),\n",
       " ('We', 1, 2, 0.07340326995687114),\n",
       " ('We', 2, 1, 0.03670163497843557),\n",
       " ('While', 3, 1, 0.05376692341046299),\n",
       " ('[38],', 0, 1, 0.05376692341046299),\n",
       " ('[41],', 0, 1, 0.05376692341046299),\n",
       " ('[47].', 0, 1, 0.05376692341046299),\n",
       " ('a', 0, 4, 0.09262461405045576),\n",
       " ('a', 1, 3, 0.06946846053784182),\n",
       " ('a', 2, 2, 0.04631230702522788),\n",
       " ('a', 3, 4, 0.09262461405045576),\n",
       " ('about', 0, 1, 0.05376692341046299),\n",
       " ('above', 2, 1, 0.05376692341046299),\n",
       " ('absolute', 1, 1, 0.05376692341046299),\n",
       " ('achieve', 2, 1, 0.05376692341046299),\n",
       " ('achieves', 0, 1, 0.05376692341046299),\n",
       " ('adopting', 1, 1, 0.05376692341046299),\n",
       " ('adopts', 2, 1, 0.05376692341046299),\n",
       " ('advanced', 3, 1, 0.05376692341046299),\n",
       " ('advances', 1, 1, 0.05376692341046299),\n",
       " ('advantages', 3, 1, 0.05376692341046299),\n",
       " ('aggregation', 0, 1, 0.05376692341046299),\n",
       " ('algorithm', 2, 1, 0.03670163497843557),\n",
       " ('algorithm', 3, 1, 0.03670163497843557),\n",
       " ('all', 2, 1, 0.03670163497843557),\n",
       " ('all', 3, 1, 0.03670163497843557),\n",
       " ('allows', 0, 1, 0.05376692341046299),\n",
       " ('also', 3, 2, 0.10753384682092598),\n",
       " ('among', 3, 2, 0.10753384682092598),\n",
       " ('an', 0, 2, 0.07340326995687114),\n",
       " ('an', 2, 1, 0.03670163497843557),\n",
       " ('analyses', 0, 1, 0.05376692341046299),\n",
       " ('and', 0, 7, 0.16209307458829755),\n",
       " ('and', 1, 7, 0.16209307458829755),\n",
       " ('and', 2, 9, 0.20840538161352545),\n",
       " ('and', 3, 6, 0.13893692107568364),\n",
       " ('applicable', 3, 1, 0.05376692341046299),\n",
       " ('applications', 2, 1, 0.05376692341046299),\n",
       " ('architectures', 3, 1, 0.05376692341046299),\n",
       " ('are', 0, 1, 0.02315615351261394),\n",
       " ('are', 1, 1, 0.02315615351261394),\n",
       " ('are', 2, 1, 0.02315615351261394),\n",
       " ('are', 3, 2, 0.04631230702522788),\n",
       " ('area', 2, 1, 0.05376692341046299),\n",
       " ('argue', 3, 1, 0.05376692341046299),\n",
       " ('as', 0, 1, 0.03670163497843557),\n",
       " ('as', 1, 3, 0.11010490493530672),\n",
       " ('assessment', 2, 2, 0.10753384682092598),\n",
       " ('association', 2, 1, 0.05376692341046299),\n",
       " ('at', 0, 1, 0.05376692341046299),\n",
       " ('attention.', 1, 1, 0.05376692341046299),\n",
       " ('attentive', 0, 1, 0.03670163497843557),\n",
       " ('attentive', 3, 1, 0.03670163497843557),\n",
       " ('automatically', 2, 1, 0.05376692341046299),\n",
       " ('auxiliary', 0, 1, 0.05376692341046299),\n",
       " ('average', 1, 1, 0.03670163497843557),\n",
       " ('average', 2, 1, 0.03670163497843557),\n",
       " ('based', 1, 1, 0.05376692341046299),\n",
       " ('baselines,', 1, 1, 0.05376692341046299),\n",
       " ('be', 3, 1, 0.05376692341046299),\n",
       " ('behind', 0, 1, 0.05376692341046299),\n",
       " ('benchmark', 0, 1, 0.05376692341046299),\n",
       " ('benchmarks', 3, 1, 0.05376692341046299),\n",
       " ('better', 0, 1, 0.03670163497843557),\n",
       " ('better', 3, 2, 0.07340326995687114),\n",
       " ('between', 2, 1, 0.05376692341046299),\n",
       " ('bipartite', 1, 1, 0.05376692341046299),\n",
       " ('both', 1, 1, 0.03670163497843557),\n",
       " ('both', 3, 1, 0.03670163497843557),\n",
       " ('but', 3, 1, 0.05376692341046299),\n",
       " ('by', 0, 2, 0.04631230702522788),\n",
       " ('by', 1, 1, 0.02315615351261394),\n",
       " ('by', 2, 1, 0.02315615351261394),\n",
       " ('by', 3, 1, 0.02315615351261394),\n",
       " ('called', 2, 1, 0.05376692341046299),\n",
       " ('can', 1, 1, 0.05376692341046299),\n",
       " ('capability', 0, 1, 0.05376692341046299),\n",
       " ('capture', 1, 1, 0.03670163497843557),\n",
       " ('capture', 3, 1, 0.03670163497843557),\n",
       " ('case', 2, 1, 0.05376692341046299),\n",
       " ('challenging.', 1, 1, 0.05376692341046299),\n",
       " ('characterize', 3, 1, 0.05376692341046299),\n",
       " ('coarse-grained', 0, 1, 0.05376692341046299),\n",
       " ('coexist', 1, 1, 0.05376692341046299),\n",
       " ('collaborative', 1, 7, 0.256911444849049),\n",
       " ('collaborative', 3, 1, 0.03670163497843557),\n",
       " ('combination', 0, 1, 0.05376692341046299),\n",
       " ('complexity.', 3, 1, 0.05376692341046299),\n",
       " ('concept', 2, 1, 0.05376692341046299),\n",
       " ('concept-based', 2, 1, 0.05376692341046299),\n",
       " ('concepts', 2, 3, 0.16130077023138897),\n",
       " ('concepts.', 2, 1, 0.05376692341046299),\n",
       " ('connections', 3, 1, 0.05376692341046299),\n",
       " ('connectivity', 0, 1, 0.05376692341046299),\n",
       " ('connectivity.In', 0, 1, 0.05376692341046299),\n",
       " ('considering', 1, 1, 0.05376692341046299),\n",
       " ('construct', 2, 1, 0.05376692341046299),\n",
       " ('constructing', 2, 1, 0.05376692341046299),\n",
       " ('contains', 3, 1, 0.05376692341046299),\n",
       " ('continuous-time', 1, 1, 0.05376692341046299),\n",
       " ('courses', 2, 1, 0.05376692341046299),\n",
       " ('crucial', 1, 1, 0.05376692341046299),\n",
       " ('curriculum', 2, 1, 0.05376692341046299),\n",
       " ('curve', 2, 1, 0.05376692341046299),\n",
       " ('data', 2, 5, 0.18350817489217788),\n",
       " ('data', 3, 1, 0.03670163497843557),\n",
       " ('data)', 2, 1, 0.03670163497843557),\n",
       " ('data)', 3, 1, 0.03670163497843557),\n",
       " ('datasets', 0, 1, 0.03670163497843557),\n",
       " ('datasets', 1, 1, 0.03670163497843557),\n",
       " ('defined', 1, 2, 0.10753384682092598),\n",
       " ('demand', 2, 1, 0.05376692341046299),\n",
       " ('demonstrative', 2, 1, 0.05376692341046299),\n",
       " ('dependencies', 0, 1, 0.05376692341046299),\n",
       " ('derived', 2, 1, 0.05376692341046299),\n",
       " ('design', 1, 1, 0.03670163497843557),\n",
       " ('design', 3, 1, 0.03670163497843557),\n",
       " ('designs', 3, 1, 0.05376692341046299),\n",
       " ('detail', 2, 1, 0.05376692341046299),\n",
       " ('develop', 0, 1, 0.05376692341046299),\n",
       " ('devise', 0, 1, 0.05376692341046299),\n",
       " ('different', 0, 1, 0.05376692341046299),\n",
       " ('distill', 0, 1, 0.05376692341046299),\n",
       " ('domain,', 2, 2, 0.10753384682092598),\n",
       " ('dynamics', 1, 1, 0.05376692341046299),\n",
       " ('each', 0, 1, 0.05376692341046299),\n",
       " ('education', 2, 2, 0.10753384682092598),\n",
       " ('education.', 2, 1, 0.05376692341046299),\n",
       " ('educational', 2, 2, 0.10753384682092598),\n",
       " ('effective', 3, 1, 0.05376692341046299),\n",
       " ('effects', 1, 1, 0.05376692341046299),\n",
       " ('efficiency', 3, 1, 0.05376692341046299),\n",
       " ('efficient', 3, 1, 0.05376692341046299),\n",
       " ('efficiently', 3, 1, 0.05376692341046299),\n",
       " ('efforts', 2, 1, 0.05376692341046299),\n",
       " ('embedding', 3, 2, 0.10753384682092598),\n",
       " ('embeddings', 1, 1, 0.05376692341046299),\n",
       " ('employs', 2, 1, 0.05376692341046299),\n",
       " ('encode', 0, 1, 0.03670163497843557),\n",
       " ('encode', 1, 1, 0.03670163497843557),\n",
       " ('encoded', 3, 1, 0.05376692341046299),\n",
       " ('encouraging', 0, 1, 0.05376692341046299),\n",
       " ('end-to-end', 0, 1, 0.05376692341046299),\n",
       " ('enhanced', 3, 2, 0.10753384682092598),\n",
       " ('entities,', 3, 1, 0.05376692341046299),\n",
       " ('entities.', 3, 1, 0.05376692341046299),\n",
       " ('evolution', 1, 1, 0.05376692341046299),\n",
       " ('evolving', 1, 1, 0.05376692341046299),\n",
       " ('exceeds', 2, 1, 0.05376692341046299),\n",
       " ('exemplary', 2, 1, 0.05376692341046299),\n",
       " ('existing', 0, 1, 0.03670163497843557),\n",
       " ('existing', 3, 1, 0.03670163497843557),\n",
       " ('explanations', 0, 1, 0.05376692341046299),\n",
       " ('exploit', 0, 1, 0.05376692341046299),\n",
       " ('explore', 0, 1, 0.05376692341046299),\n",
       " ('exploring', 3, 1, 0.05376692341046299),\n",
       " ('express', 1, 1, 0.05376692341046299),\n",
       " ('external', 3, 1, 0.05376692341046299),\n",
       " ('extract', 2, 1, 0.05376692341046299),\n",
       " ('extraction', 2, 1, 0.05376692341046299),\n",
       " ('extracts', 2, 1, 0.05376692341046299),\n",
       " ('failing', 0, 1, 0.05376692341046299),\n",
       " ('faster', 3, 1, 0.05376692341046299),\n",
       " ('fine-grained', 0, 1, 0.03670163497843557),\n",
       " ('fine-grained', 3, 1, 0.03670163497843557),\n",
       " ('first', 2, 1, 0.03670163497843557),\n",
       " ('first', 3, 1, 0.03670163497843557),\n",
       " ('five', 1, 1, 0.05376692341046299),\n",
       " ('focused', 3, 1, 0.05376692341046299),\n",
       " ('for', 0, 3, 0.08491771968336792),\n",
       " ('for', 2, 4, 0.11322362624449056),\n",
       " ('for', 3, 5, 0.1415295328056132),\n",
       " ('founded', 0, 1, 0.05376692341046299),\n",
       " ('fraction', 3, 1, 0.05376692341046299),\n",
       " ('framework', 1, 1, 0.05376692341046299),\n",
       " ('framework,', 3, 1, 0.05376692341046299),\n",
       " ('from', 1, 2, 0.05661181312224528),\n",
       " ('from', 2, 2, 0.05661181312224528),\n",
       " ('from', 3, 1, 0.02830590656112264),\n",
       " ('graph', 0, 2, 0.04631230702522788),\n",
       " ('graph', 1, 1, 0.02315615351261394),\n",
       " ('graph', 2, 3, 0.06946846053784182),\n",
       " ('graph', 3, 3, 0.06946846053784182),\n",
       " ('graph.', 1, 1, 0.05376692341046299),\n",
       " ('hard', 1, 1, 0.05376692341046299),\n",
       " ('has', 3, 1, 0.05376692341046299),\n",
       " ('have', 3, 1, 0.05376692341046299),\n",
       " ('heterogeneous', 2, 1, 0.05376692341046299),\n",
       " ('high-quality', 3, 1, 0.05376692341046299),\n",
       " ('identification,', 2, 1, 0.05376692341046299),\n",
       " ('identifies', 2, 1, 0.05376692341046299),\n",
       " ('identify', 0, 1, 0.03670163497843557),\n",
       " ('identify', 2, 1, 0.03670163497843557),\n",
       " ('identifying', 0, 1, 0.05376692341046299),\n",
       " ('ignore', 1, 1, 0.05376692341046299),\n",
       " ('important', 0, 1, 0.05376692341046299),\n",
       " ('improve', 1, 1, 0.05376692341046299),\n",
       " ('improvements', 0, 1, 0.03670163497843557),\n",
       " ('improvements', 1, 1, 0.03670163497843557),\n",
       " ('in', 0, 2, 0.04631230702522788),\n",
       " ('in', 1, 4, 0.09262461405045576),\n",
       " ('in', 2, 1, 0.02315615351261394),\n",
       " ('in', 3, 1, 0.02315615351261394),\n",
       " ('increasing', 2, 1, 0.05376692341046299),\n",
       " ('increasingly', 0, 1, 0.05376692341046299),\n",
       " ('independence', 0, 1, 0.05376692341046299),\n",
       " ('influential', 0, 1, 0.05376692341046299),\n",
       " ('information', 0, 2, 0.05661181312224528),\n",
       " ('information', 1, 1, 0.02830590656112264),\n",
       " ('information', 3, 3, 0.08491771968336792),\n",
       " ('information),', 3, 1, 0.05376692341046299),\n",
       " ('inside', 1, 1, 0.05376692341046299),\n",
       " ('instances', 3, 1, 0.05376692341046299),\n",
       " ('instructional', 2, 2, 0.10753384682092598),\n",
       " ('insufficient', 3, 1, 0.05376692341046299),\n",
       " ('integrates', 0, 1, 0.05376692341046299),\n",
       " ('intent', 0, 1, 0.05376692341046299),\n",
       " ('intents', 0, 4, 0.21506769364185196),\n",
       " ('intents,', 0, 1, 0.05376692341046299),\n",
       " ('interaction', 0, 1, 0.05376692341046299),\n",
       " ('interactions', 1, 1, 0.05376692341046299),\n",
       " ('interpretability.', 0, 1, 0.05376692341046299),\n",
       " ('interpretable', 0, 1, 0.05376692341046299),\n",
       " ('into', 0, 1, 0.05376692341046299),\n",
       " ('investigate', 3, 1, 0.05376692341046299),\n",
       " ('is', 0, 1, 0.02830590656112264),\n",
       " ('is', 1, 4, 0.11322362624449056),\n",
       " ('is', 3, 2, 0.05661181312224528),\n",
       " ('it', 1, 2, 0.05661181312224528),\n",
       " ('it', 2, 1, 0.02830590656112264),\n",
       " ('it', 3, 2, 0.05661181312224528),\n",
       " ('item', 0, 1, 0.03670163497843557),\n",
       " ('item', 1, 2, 0.07340326995687114),\n",
       " ('items,', 1, 1, 0.03670163497843557),\n",
       " ('items,', 3, 2, 0.07340326995687114),\n",
       " ('items.', 0, 1, 0.03670163497843557),\n",
       " ('items.', 3, 1, 0.03670163497843557),\n",
       " ('joint', 3, 1, 0.05376692341046299),\n",
       " ('knowledge', 2, 3, 0.11010490493530672),\n",
       " ('knowledge', 3, 1, 0.03670163497843557),\n",
       " ('knowledge,', 0, 1, 0.05376692341046299),\n",
       " ('labeling', 2, 1, 0.05376692341046299),\n",
       " ('large-scale', 3, 1, 0.05376692341046299),\n",
       " ('largely', 3, 1, 0.05376692341046299),\n",
       " ('latent', 1, 1, 0.05376692341046299),\n",
       " ('layer', 1, 3, 0.16130077023138897),\n",
       " ('learn', 1, 1, 0.05376692341046299),\n",
       " ('learned', 1, 1, 0.05376692341046299),\n",
       " ('learning', 2, 2, 0.07340326995687114),\n",
       " ('learning', 3, 2, 0.07340326995687114),\n",
       " ('learning,', 3, 1, 0.05376692341046299),\n",
       " ('learning.', 3, 1, 0.05376692341046299),\n",
       " ('learns', 3, 1, 0.05376692341046299),\n",
       " ('level', 0, 1, 0.05376692341046299),\n",
       " ('leverage', 1, 1, 0.05376692341046299),\n",
       " ('leveraging', 2, 1, 0.05376692341046299),\n",
       " ('like', 0, 1, 0.03670163497843557),\n",
       " ('like', 3, 1, 0.03670163497843557),\n",
       " ('long-range', 0, 2, 0.10753384682092598),\n",
       " ('lose', 3, 1, 0.05376692341046299),\n",
       " ('lots', 3, 1, 0.05376692341046299),\n",
       " ('low', 3, 1, 0.05376692341046299),\n",
       " ('mainly', 3, 1, 0.05376692341046299),\n",
       " ('makes', 3, 1, 0.05376692341046299),\n",
       " ('mathematics,', 2, 1, 0.05376692341046299),\n",
       " ('may', 3, 1, 0.05376692341046299),\n",
       " ('mean', 2, 1, 0.05376692341046299),\n",
       " ('mechanism', 1, 1, 0.05376692341046299),\n",
       " ('memorization', 3, 1, 0.05376692341046299),\n",
       " ('mentioned', 2, 1, 0.05376692341046299),\n",
       " ('methods', 0, 1, 0.02830590656112264),\n",
       " ('methods', 1, 1, 0.02830590656112264),\n",
       " ('methods', 3, 4, 0.11322362624449056),\n",
       " ('mining', 2, 1, 0.05376692341046299),\n",
       " ('model', 0, 2, 0.05661181312224528),\n",
       " ('model', 1, 2, 0.05661181312224528),\n",
       " ('model', 3, 3, 0.08491771968336792),\n",
       " ('model,', 0, 1, 0.05376692341046299),\n",
       " ('modeling,', 0, 1, 0.05376692341046299),\n",
       " ('modelname', 1, 1, 0.05376692341046299),\n",
       " ('models', 0, 2, 0.07340326995687114),\n",
       " ('models', 3, 2, 0.07340326995687114),\n",
       " ('more', 3, 1, 0.05376692341046299),\n",
       " ('most', 1, 1, 0.05376692341046299),\n",
       " ('negative', 3, 1, 0.05376692341046299),\n",
       " ('network', 3, 2, 0.10753384682092598),\n",
       " ('networks', 0, 1, 0.05376692341046299),\n",
       " ('neural', 0, 1, 0.02830590656112264),\n",
       " ('neural', 2, 1, 0.02830590656112264),\n",
       " ('neural', 3, 2, 0.05661181312224528),\n",
       " ('new', 0, 2, 0.05661181312224528),\n",
       " ('new', 1, 1, 0.02830590656112264),\n",
       " ('new', 3, 1, 0.02830590656112264),\n",
       " ('non-observed', 3, 1, 0.05376692341046299),\n",
       " ('non-trivial', 1, 1, 0.05376692341046299),\n",
       " ('not', 3, 2, 0.10753384682092598),\n",
       " ('novel', 1, 2, 0.07340326995687114),\n",
       " ('novel', 3, 2, 0.07340326995687114),\n",
       " ('of', 0, 6, 0.13893692107568364),\n",
       " ('of', 1, 4, 0.09262461405045576),\n",
       " ('of', 2, 4, 0.09262461405045576),\n",
       " ('of', 3, 4, 0.09262461405045576),\n",
       " ('offers', 0, 1, 0.05376692341046299),\n",
       " ('on', 0, 2, 0.04631230702522788),\n",
       " ('on', 1, 2, 0.04631230702522788),\n",
       " ('on', 2, 3, 0.06946846053784182),\n",
       " ('on', 3, 3, 0.06946846053784182),\n",
       " ('only', 3, 1, 0.05376692341046299),\n",
       " ('optimization', 3, 1, 0.05376692341046299),\n",
       " ('optimize', 3, 1, 0.05376692341046299),\n",
       " ('or', 2, 1, 0.05376692341046299),\n",
       " ('order', 1, 1, 0.05376692341046299),\n",
       " ('other', 1, 1, 0.05376692341046299),\n",
       " ('our', 1, 1, 0.05376692341046299),\n",
       " ('outperforms', 1, 1, 0.03670163497843557),\n",
       " ('outperforms', 3, 1, 0.03670163497843557),\n",
       " ('over', 0, 1, 0.02830590656112264),\n",
       " ('over', 1, 1, 0.02830590656112264),\n",
       " ('over', 3, 1, 0.02830590656112264),\n",
       " ('paper,', 3, 1, 0.05376692341046299),\n",
       " ('parameters', 3, 1, 0.05376692341046299),\n",
       " ('paths).', 0, 1, 0.05376692341046299),\n",
       " ('paths.', 0, 1, 0.05376692341046299),\n",
       " ('patterns', 1, 4, 0.21506769364185196),\n",
       " ('patterns.', 1, 2, 0.10753384682092598),\n",
       " ('pedagogical', 2, 2, 0.10753384682092598),\n",
       " ('performance', 2, 1, 0.05376692341046299),\n",
       " ('plays', 0, 1, 0.05376692341046299),\n",
       " ('precision', 2, 1, 0.05376692341046299),\n",
       " ('predictions', 0, 1, 0.05376692341046299),\n",
       " ('preference', 3, 1, 0.05376692341046299),\n",
       " ('preference,', 1, 1, 0.05376692341046299),\n",
       " ('prerequisite', 2, 1, 0.05376692341046299),\n",
       " ('preserve', 0, 1, 0.05376692341046299),\n",
       " ('probabilistic', 2, 1, 0.05376692341046299),\n",
       " ('problem.', 1, 1, 0.05376692341046299),\n",
       " ('propagate', 1, 1, 0.05376692341046299),\n",
       " ('propose', 0, 1, 0.02315615351261394),\n",
       " ('propose', 1, 2, 0.04631230702522788),\n",
       " ('propose', 2, 1, 0.02315615351261394),\n",
       " ('propose', 3, 1, 0.02315615351261394),\n",
       " ('proposed', 3, 1, 0.05376692341046299),\n",
       " ('public', 3, 1, 0.05376692341046299),\n",
       " ('purchasing', 1, 1, 0.05376692341046299),\n",
       " ('quality', 1, 1, 0.05376692341046299),\n",
       " ('rather', 1, 1, 0.03670163497843557),\n",
       " ('rather', 3, 1, 0.03670163497843557),\n",
       " ('real-world', 3, 1, 0.05376692341046299),\n",
       " ('reasonable', 3, 1, 0.05376692341046299),\n",
       " ('recent', 0, 1, 0.05376692341046299),\n",
       " ('recommendation', 3, 2, 0.10753384682092598),\n",
       " ('recommendation,', 1, 1, 0.05376692341046299),\n",
       " ('recommendation.', 3, 1, 0.05376692341046299),\n",
       " ('recommender', 0, 1, 0.05376692341046299),\n",
       " ('recursively', 0, 1, 0.05376692341046299),\n",
       " ('relation', 0, 3, 0.11010490493530672),\n",
       " ('relation', 2, 1, 0.03670163497843557),\n",
       " ('relational', 0, 3, 0.16130077023138897),\n",
       " ('relations', 2, 3, 0.16130077023138897),\n",
       " ('relations,', 0, 1, 0.05376692341046299),\n",
       " ('rely', 3, 1, 0.05376692341046299),\n",
       " ('representations', 0, 1, 0.05376692341046299),\n",
       " ('respectively.', 1, 1, 0.03670163497843557),\n",
       " ('respectively.', 2, 1, 0.03670163497843557),\n",
       " ('results', 0, 1, 0.02315615351261394),\n",
       " ('results', 1, 1, 0.02315615351261394),\n",
       " ('results', 2, 1, 0.02315615351261394),\n",
       " ('results', 3, 1, 0.02315615351261394),\n",
       " ('robust', 3, 1, 0.05376692341046299),\n",
       " ('role', 0, 1, 0.05376692341046299),\n",
       " ('rule', 2, 1, 0.05376692341046299),\n",
       " ('sKGNN-LS', 0, 1, 0.05376692341046299),\n",
       " ('sampling', 3, 1, 0.05376692341046299),\n",
       " ('scheme', 0, 2, 0.10753384682092598),\n",
       " ('score', 2, 1, 0.05376692341046299),\n",
       " ('self-attention', 1, 1, 0.05376692341046299),\n",
       " ('semantics', 0, 1, 0.05376692341046299),\n",
       " ('sequence', 2, 1, 0.05376692341046299),\n",
       " ('sequences', 0, 1, 0.05376692341046299),\n",
       " ('sequences,', 1, 1, 0.05376692341046299),\n",
       " ('sequential', 1, 6, 0.32260154046277795),\n",
       " ('should', 1, 1, 0.05376692341046299),\n",
       " ('show', 0, 2, 0.04631230702522788),\n",
       " ('show', 1, 1, 0.02315615351261394),\n",
       " ('show', 2, 1, 0.02315615351261394),\n",
       " ('show', 3, 1, 0.02315615351261394),\n",
       " ('shown', 3, 1, 0.05376692341046299),\n",
       " ('shows', 3, 1, 0.05376692341046299),\n",
       " ('signals', 1, 2, 0.10753384682092598),\n",
       " ('signals,', 1, 1, 0.05376692341046299),\n",
       " ('signals.', 1, 2, 0.10753384682092598),\n",
       " ('signals.Hence,', 1, 1, 0.05376692341046299),\n",
       " ('significance.', 2, 1, 0.05376692341046299),\n",
       " ('significant', 0, 1, 0.03670163497843557),\n",
       " ('significant', 3, 1, 0.03670163497843557),\n",
       " ('significantly', 1, 1, 0.03670163497843557),\n",
       " ('significantly', 3, 1, 0.03670163497843557),\n",
       " ('simultaneously', 1, 2, 0.10753384682092598),\n",
       " ('small', 3, 1, 0.05376692341046299),\n",
       " ('specifically,', 2, 1, 0.05376692341046299),\n",
       " ('standards', 2, 1, 0.05376692341046299),\n",
       " ('state-of-the-art', 0, 1, 0.03670163497843557),\n",
       " ('state-of-the-art', 3, 1, 0.03670163497843557),\n",
       " ('strategies', 3, 1, 0.05376692341046299),\n",
       " ('structural', 3, 1, 0.05376692341046299),\n",
       " ('students.', 2, 1, 0.05376692341046299),\n",
       " ('study,', 0, 1, 0.05376692341046299),\n",
       " ('subgraphs', 3, 1, 0.05376692341046299),\n",
       " ('subjects', 2, 1, 0.05376692341046299),\n",
       " ('system', 2, 1, 0.05376692341046299),\n",
       " ('system,', 2, 1, 0.05376692341046299),\n",
       " ('systems.', 0, 1, 0.03670163497843557),\n",
       " ('systems.', 3, 1, 0.03670163497843557),\n",
       " ('task', 3, 1, 0.05376692341046299),\n",
       " ('task.', 3, 1, 0.05376692341046299),\n",
       " ('technical', 0, 1, 0.05376692341046299),\n",
       " ('temporal', 1, 6, 0.32260154046277795),\n",
       " ('than', 3, 1, 0.05376692341046299),\n",
       " ('that', 0, 1, 0.02315615351261394),\n",
       " ('that', 1, 1, 0.02315615351261394),\n",
       " ('that', 2, 1, 0.02315615351261394),\n",
       " ('that', 3, 2, 0.04631230702522788),\n",
       " ('that,', 0, 1, 0.05376692341046299),\n",
       " ('the', 0, 5, 0.1157807675630697),\n",
       " ('the', 1, 6, 0.13893692107568364),\n",
       " ('the', 2, 13, 0.3010299956639812),\n",
       " ('the', 3, 6, 0.13893692107568364),\n",
       " ('their', 2, 1, 0.05376692341046299),\n",
       " ('them', 0, 1, 0.03670163497843557),\n",
       " ('them', 1, 1, 0.03670163497843557),\n",
       " ('then', 2, 1, 0.03670163497843557),\n",
       " ('then', 3, 1, 0.03670163497843557),\n",
       " ('these', 3, 2, 0.10753384682092598),\n",
       " ('this', 0, 1, 0.02830590656112264),\n",
       " ('this', 2, 1, 0.02830590656112264),\n",
       " ('this', 3, 1, 0.02830590656112264),\n",
       " ('three', 0, 1, 0.05376692341046299),\n",
       " ('through', 2, 1, 0.05376692341046299),\n",
       " ('time', 3, 1, 0.05376692341046299),\n",
       " ('time-ordered', 1, 1, 0.05376692341046299),\n",
       " ('times', 3, 1, 0.05376692341046299),\n",
       " ('to', 0, 4, 0.09262461405045576),\n",
       " ('to', 1, 8, 0.18524922810091152),\n",
       " ('to', 2, 3, 0.06946846053784182),\n",
       " ('to', 3, 7, 0.16209307458829755),\n",
       " ('training', 3, 2, 0.10753384682092598),\n",
       " ('transitions.', 1, 1, 0.05376692341046299),\n",
       " ('trend', 0, 1, 0.05376692341046299),\n",
       " ('two', 3, 1, 0.05376692341046299),\n",
       " ('under', 2, 1, 0.05376692341046299),\n",
       " ('unify', 1, 2, 0.10753384682092598),\n",
       " ('up', 1, 1, 0.05376692341046299),\n",
       " ('upon', 1, 1, 0.05376692341046299),\n",
       " ('us', 0, 1, 0.05376692341046299),\n",
       " ('useful', 0, 1, 0.03670163497843557),\n",
       " ('useful', 3, 1, 0.03670163497843557),\n",
       " ('user', 0, 1, 0.02830590656112264),\n",
       " ('user', 1, 1, 0.02830590656112264),\n",
       " ('user', 3, 1, 0.02830590656112264),\n",
       " ('user-item', 0, 2, 0.07340326995687114),\n",
       " ('user-item', 1, 2, 0.07340326995687114),\n",
       " ('users', 0, 1, 0.03670163497843557),\n",
       " ('users', 1, 1, 0.03670163497843557),\n",
       " ('users,', 3, 2, 0.10753384682092598),\n",
       " ('using', 0, 1, 0.05376692341046299),\n",
       " ('vast', 2, 1, 0.05376692341046299),\n",
       " ('we', 0, 3, 0.06946846053784182),\n",
       " ('we', 1, 3, 0.06946846053784182),\n",
       " ('we', 2, 1, 0.02315615351261394),\n",
       " ('we', 3, 2, 0.04631230702522788),\n",
       " ('well', 1, 1, 0.05376692341046299),\n",
       " ('well-structured', 3, 1, 0.05376692341046299),\n",
       " ('where', 2, 1, 0.05376692341046299),\n",
       " ('which', 0, 1, 0.02830590656112264),\n",
       " ('which', 1, 4, 0.11322362624449056),\n",
       " ('which', 3, 1, 0.02830590656112264),\n",
       " ('whole', 3, 1, 0.05376692341046299),\n",
       " ('with', 1, 1, 0.02830590656112264),\n",
       " ('with', 2, 1, 0.02830590656112264),\n",
       " ('with', 3, 1, 0.02830590656112264)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Docs:\n",
    "\n",
    "    def __init__(self,Lancaster=True):\n",
    "\n",
    "        docs = []\n",
    "        self.maxfreq = 0\n",
    "        MotsVides = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "        files = [\"D1.txt\",\"D2.txt\",\"D3.txt\",\"D4.txt\"]\n",
    "        file = \"\"\n",
    "        my_dict = {}\n",
    "        for i in range(len(files)):\n",
    "            file = open(files[i]).read()\n",
    "            file = file.replace(\"\\n\",\"\")\n",
    "            if Lancaster :\n",
    "                ExpReg = nltk.RegexpTokenizer('(?:[A-Z]\\.)+|\\d+(?:\\.\\d+)?DA?|\\w+|\\.{3}') # \\d : équivalent à [0-9] >>> \n",
    "                Termes = ExpReg.tokenize(file) \n",
    "                TermesSansMotsVides = [terme for terme in Termes if terme.lower() not in MotsVides]\n",
    "                Lancaster = nltk.LancasterStemmer()\n",
    "                TermesNormalisation = [Lancaster.stem(terme) for terme in TermesSansMotsVides]\n",
    "            else:\n",
    "                TermesNormalisation = file.split(\" \")\n",
    "\n",
    "            for term in TermesNormalisation:\n",
    "                \n",
    "                if (term,i) in my_dict:\n",
    "                    my_dict[(term,i)] += 1\n",
    "                else:\n",
    "                    my_dict[(term,i)] = 1\n",
    "\n",
    "        self.dict = my_dict\n",
    "\n",
    "        for keys in self.dict.keys():\n",
    "            if keys[1] not in docs:\n",
    "                docs.append(keys[1])\n",
    "            if self.dict[keys] > self.maxfreq:\n",
    "                self.maxfreq = self.dict[keys]\n",
    "\n",
    "        self.N = len(docs)\n",
    "    \n",
    "    def rebuild(self,Lancaster=True):\n",
    "        docs = []\n",
    "        self.maxfreq = 0\n",
    "        MotsVides = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "        files = [\"D1.txt\",\"D2.txt\",\"D3.txt\",\"D4.txt\"]\n",
    "        file = \"\"\n",
    "        my_dict = {}\n",
    "        for i in range(len(files)):\n",
    "            file = open(files[i]).read()\n",
    "            file = file.replace(\"\\n\",\"\")\n",
    "            if Lancaster :\n",
    "                ExpReg = nltk.RegexpTokenizer('(?:[A-Z]\\.)+|\\d+(?:\\.\\d+)?DA?|\\w+|\\.{3}') # \\d : équivalent à [0-9] >>> \n",
    "                Termes = ExpReg.tokenize(file) \n",
    "                TermesSansMotsVides = [terme for terme in Termes if terme.lower() not in MotsVides]\n",
    "                Lancaster = nltk.LancasterStemmer()\n",
    "                TermesNormalisation = [Lancaster.stem(terme) for terme in TermesSansMotsVides]\n",
    "            else:\n",
    "                TermesNormalisation = file.split(\" \")\n",
    "\n",
    "            for term in TermesNormalisation:\n",
    "                \n",
    "                if (term,i) in my_dict:\n",
    "                    my_dict[(term,i)] += 1\n",
    "                else:\n",
    "                    my_dict[(term,i)] = 1\n",
    "\n",
    "        self.dict = my_dict\n",
    "\n",
    "        for keys in self.dict.keys():\n",
    "            if keys[1] not in docs:\n",
    "                docs.append(keys[1])\n",
    "            if self.dict[keys] > self.maxfreq:\n",
    "                self.maxfreq = self.dict[keys]\n",
    "\n",
    "        self.N = len(docs)\n",
    "        self.DictWeight()\n",
    "\n",
    "    def calcWeight(self,word,doc):\n",
    "\n",
    "        inDocs = []\n",
    "\n",
    "        for keys in self.dict.keys():\n",
    "\n",
    "\n",
    "            if keys[0] == word:\n",
    "                if keys[1] not in inDocs:\n",
    "                    inDocs.append(keys[1])\n",
    "\n",
    "        # nombre de documents contenant le mot\n",
    "        Ni = len(inDocs)\n",
    "        # nombre de documents\n",
    "\n",
    "        try:\n",
    "            tf = self.dict[(word,doc)]/self.maxfreq\n",
    "        except:\n",
    "            tf = 0\n",
    "            \n",
    "        #idf = math.log10((N/Ni)+1)\n",
    "        try:\n",
    "            idf = math.log10((self.N/Ni)+1)\n",
    "        except:\n",
    "            idf = 0\n",
    "\n",
    "        return(tf*idf)\n",
    "\n",
    "    def DictWeight(self):\n",
    "        self.TDFP = [(word,doc,self.dict[(word,doc)],self.calcWeight(word,doc)) for word,doc in self.dict.keys()]\n",
    "        self.DTFP = [(doc,word,freq,weight) for word,doc,freq,weight in self.TDFP]\n",
    "        self.TDFP = sorted(self.TDFP, key=lambda x: x[0])\n",
    "\n",
    "        \n",
    "d = Docs(Lancaster=False)\n",
    "\n",
    "d.DictWeight()\n",
    "\n",
    "d.TDFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\APPS\\python\\lib\\tkinter\\__init__.py\", line 1884, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\Mekki\\AppData\\Local\\Temp\\ipykernel_11696\\2853912488.py\", line 31, in on_token_change\n",
      "    search()\n",
      "  File \"C:\\Users\\Mekki\\AppData\\Local\\Temp\\ipykernel_11696\\2853912488.py\", line 7, in search\n",
      "    table.delete(*table.get_children())\n",
      "  File \"d:\\APPS\\python\\lib\\tkinter\\ttk.py\", line 1225, in get_children\n",
      "    self.tk.call(self._w, \"children\", item or '') or ())\n",
      "_tkinter.TclError: invalid command name \".!frame.!treeview\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "\n",
    "def search():\n",
    "\n",
    "    text = query_text.get()\n",
    "    table.delete(*table.get_children())\n",
    "\n",
    "    if index_var.get() == 0:\n",
    "        data = d.TDFP\n",
    "    else:\n",
    "        data = d.DTFP\n",
    "\n",
    "    for terme in data:\n",
    "\n",
    "        if type(terme[0]) is str:\n",
    "            if text.lower() in terme[0].lower():\n",
    "                table.insert(\"\", \"end\", values=[terme[0],terme[1],terme[2],terme[3]])\n",
    "        else:\n",
    "            if text.lower() in terme[1].lower():\n",
    "                table.insert(\"\", \"end\", values=[terme[0],terme[1],terme[2],terme[3]])\n",
    "    # Add your search and processing logic here\n",
    "    pass\n",
    "\n",
    "def on_token_change(*args):\n",
    "    print(processing_var.get())\n",
    "    if processing_var.get() == 0:\n",
    "        d.rebuild(Lancaster=False)\n",
    "    else:\n",
    "        d.rebuild(Lancaster=True)\n",
    "    search()\n",
    "\n",
    "def on_index_change(*args):\n",
    "    search()\n",
    "\n",
    "# Create the main application window\n",
    "root = tk.Tk()\n",
    "root.title(\"Text Processing Application\")\n",
    "\n",
    "# Search Query Text Box and Search Button\n",
    "query_label = tk.Label(root, text=\"Search Query:\")\n",
    "query_label.grid(row=0, column=0)\n",
    "query_text = tk.Entry(root, width=40)\n",
    "query_text.grid(row=0, column=1)\n",
    "search_button = tk.Button(root, text=\"Search\", command=search)\n",
    "search_button.grid(row=0, column=2)\n",
    "\n",
    "# Border around \"Processing\" section\n",
    "processing_label_frame = ttk.LabelFrame(root, text=\"Processing\")\n",
    "processing_label_frame.grid(row=1, column=2, padx=10, pady=10)\n",
    "\n",
    "# Radio buttons for Processing\n",
    "processing_var = tk.IntVar()\n",
    "processing_var.trace(\"w\", on_token_change)\n",
    "\n",
    "tokenization_radiobutton = tk.Radiobutton(processing_label_frame, text=\"Tokenization\", variable=processing_var, value=0)\n",
    "porter_stemmer_radiobutton = tk.Radiobutton(processing_label_frame, text=\"Porter Stemmer\", variable=processing_var, value=1)\n",
    "porter_stemmer_radiobutton.select()\n",
    "tokenization_radiobutton.grid(row=0, column=0)\n",
    "porter_stemmer_radiobutton.grid(row=1, column=0)\n",
    "\n",
    "# Border around \"Index\" section\n",
    "index_label_frame = ttk.LabelFrame(root, text=\"Index\")\n",
    "index_label_frame.grid(row=1, column=0, padx=10, pady=10)\n",
    "\n",
    "# Radio buttons for Index\n",
    "\n",
    "index_var = tk.IntVar()\n",
    "index_var.trace(\"w\", on_index_change)\n",
    "\n",
    "docs_per_term_radiobutton = tk.Radiobutton(index_label_frame, text=\"DOCS per TERM\", variable=index_var, value=0)\n",
    "terms_per_doc_radiobutton = tk.Radiobutton(index_label_frame, text=\"TERMS per DOC\", variable=index_var, value=1)\n",
    "docs_per_term_radiobutton.grid(row=1, column=0)\n",
    "terms_per_doc_radiobutton.grid(row=2, column=0)\n",
    "\n",
    "# Table to display data\n",
    "table_frame = ttk.Frame(root)\n",
    "table_frame.grid(row=2, column=0, columnspan=3, pady=10)\n",
    "table = ttk.Treeview(table_frame, columns=(\"1\", \"2\", \"3\", \"4\"))\n",
    "table.heading(\"#1\", text=\"terme\")\n",
    "table.heading(\"#2\", text=\"document\")\n",
    "table.heading(\"#3\", text=\"freq\")\n",
    "table.heading(\"#4\", text=\"Score\")\n",
    "table['show'] = 'headings'\n",
    "# Vertical scrollbar for the table\n",
    "table_scrollbar = ttk.Scrollbar(table_frame, orient=\"vertical\", command=table.yview)\n",
    "table.configure(yscrollcommand=table_scrollbar.set)\n",
    "\n",
    "# Grid layout for the table and scrollbar\n",
    "table.grid(row=0, column=0, sticky=\"nsew\")\n",
    "table_scrollbar.grid(row=0, column=1, sticky=\"ns\")\n",
    "\n",
    "\n",
    "# Make the table resizable\n",
    "table_frame.grid_rowconfigure(0, weight=1)\n",
    "table_frame.grid_columnconfigure(0, weight=1)\n",
    "\n",
    "\n",
    "for dat in d.TDFP:\n",
    "    table.insert(\"\", \"end\", values=[dat[0],dat[1],dat[2],dat[3]])\n",
    "\n",
    "\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
